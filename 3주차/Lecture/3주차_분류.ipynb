{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류 실습 - 캐글 산탄데르 고객 만족 예측 <br>\n",
    "p267~p278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:  (76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "cust_df=pd.read_csv('./train_santander.csv',encoding='latin-1')\n",
    "print('dataset shape: ',cust_df.shape)\n",
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    73012\n",
      "1     3008\n",
      "Name: TARGET, dtype: int64\n",
      "unsatisfied 비율은 0.04\n"
     ]
    }
   ],
   "source": [
    "print(cust_df['TARGET'].value_counts())\n",
    "unsatisfied_cnt=cust_df[cust_df['TARGET']==1]['TARGET'].count()\n",
    "total_cnt=cust_df['TARGET'].count()\n",
    "\n",
    "print(\"unsatisfied 비율은 {0:.2f}\".format(unsatisfied_cnt/total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2         74165\n",
       " 8           138\n",
       "-999999      116\n",
       " 9           110\n",
       " 3           108\n",
       "           ...  \n",
       " 231           1\n",
       " 188           1\n",
       " 168           1\n",
       " 135           1\n",
       " 87            1\n",
       "Name: var3, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df['var3'].value_counts() #-999999값 116개 처리 필요 -> 평균값 2로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피처 데이터 shape (76020, 369)\n"
     ]
    }
   ],
   "source": [
    "#1. 999999 -> 2 변환\n",
    "#2. ID 피처 드롭\n",
    "#3. 클래스 데이터 / 피처 데이터 분리\n",
    "\n",
    "cust_df['var3'].replace(-999999,2,inplace=True) #1\n",
    "cust_df.drop('ID',axis=1,inplace=True) #2\n",
    "\n",
    "X_features=cust_df.iloc[:,:-1] #클래스열을 제외한 나머지\n",
    "y_labels=cust_df.iloc[:,-1] #클래스열(마지막칼럼)만\n",
    "\n",
    "print('피처 데이터 shape {0}'.format(X_features.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 shape: (60816, 369), 테스트데이터 shape: (15204, 369)\n",
      "\n",
      "\n",
      "학습데이터 레이블 분포:\n",
      " 0    0.960964\n",
      "1    0.039036\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "테스트데이터 레이블 분포:\n",
      " 0    0.9583\n",
      "1    0.0417\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_features,y_labels,test_size=0.2,random_state=0)\n",
    "\n",
    "#shape\n",
    "print('학습데이터 shape: {0}, 테스트데이터 shape: {1}'.format(X_train.shape,X_test.shape))\n",
    "\n",
    "train_cnt=y_train.count()\n",
    "test_cnt=y_test.count()\n",
    "\n",
    "#학습데이터,테스트 레이블 값 분포\n",
    "print(\"\\n\\n학습데이터 레이블 분포:\\n\",y_train.value_counts()/train_cnt)\n",
    "print()\n",
    "print(\"테스트데이터 레이블 분포:\\n\",y_test.value_counts()/test_cnt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost의 조기중단 검증데이터 세트로 사용하기 위해서 X_train,y_train을 다시 쪼갬\n",
    "#학습/검증 데이터 세트로 분리\n",
    "X_tr, X_val , y_tr, y_val = train_test_split(X_train, y_train , test_size=0.3, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조기 중단을 위해 검증 데이터를 사용하는 방식은 다음과 같습니다.\n",
    "\n",
    "모델을 학습하면서 주기적으로 검증 데이터에 대한 성능을 측정합니다.\n",
    "성능이 일정 기간 동안 개선되지 않으면(즉, 과적합이 발생할 가능성이 높아지면) 학습을 중단합니다.\n",
    "이전에 저장된 최적의 모델을 반환하거나 사용합니다.\n",
    "검증 데이터를 사용하여 조기 중단을 구현하면 모델이 학습 데이터에만 과적합되는 것을 방지할 수 있습니다. 이는 모델이 학습 데이터에만 지나치게 적합되어 새로운 데이터에 대한 일반화 성능이 저하되는 것을 막아줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.22.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.11.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.83603\tvalidation_1-auc:0.80978\n",
      "[1]\tvalidation_0-auc:0.83783\tvalidation_1-auc:0.81126\n",
      "[2]\tvalidation_0-auc:0.83892\tvalidation_1-auc:0.81192\n",
      "[3]\tvalidation_0-auc:0.84090\tvalidation_1-auc:0.81349\n",
      "[4]\tvalidation_0-auc:0.84187\tvalidation_1-auc:0.81356\n",
      "[5]\tvalidation_0-auc:0.84355\tvalidation_1-auc:0.81422\n",
      "[6]\tvalidation_0-auc:0.84534\tvalidation_1-auc:0.81550\n",
      "[7]\tvalidation_0-auc:0.84658\tvalidation_1-auc:0.81623\n",
      "[8]\tvalidation_0-auc:0.84727\tvalidation_1-auc:0.81669\n",
      "[9]\tvalidation_0-auc:0.84794\tvalidation_1-auc:0.81668\n",
      "[10]\tvalidation_0-auc:0.84980\tvalidation_1-auc:0.81828\n",
      "[11]\tvalidation_0-auc:0.85105\tvalidation_1-auc:0.81965\n",
      "[12]\tvalidation_0-auc:0.85217\tvalidation_1-auc:0.81999\n",
      "[13]\tvalidation_0-auc:0.85301\tvalidation_1-auc:0.82049\n",
      "[14]\tvalidation_0-auc:0.85558\tvalidation_1-auc:0.82210\n",
      "[15]\tvalidation_0-auc:0.85662\tvalidation_1-auc:0.82288\n",
      "[16]\tvalidation_0-auc:0.85811\tvalidation_1-auc:0.82380\n",
      "[17]\tvalidation_0-auc:0.85864\tvalidation_1-auc:0.82365\n",
      "[18]\tvalidation_0-auc:0.85961\tvalidation_1-auc:0.82403\n",
      "[19]\tvalidation_0-auc:0.86068\tvalidation_1-auc:0.82511\n",
      "[20]\tvalidation_0-auc:0.86154\tvalidation_1-auc:0.82607\n",
      "[21]\tvalidation_0-auc:0.86216\tvalidation_1-auc:0.82672\n",
      "[22]\tvalidation_0-auc:0.86279\tvalidation_1-auc:0.82744\n",
      "[23]\tvalidation_0-auc:0.86336\tvalidation_1-auc:0.82820\n",
      "[24]\tvalidation_0-auc:0.86362\tvalidation_1-auc:0.82811\n",
      "[25]\tvalidation_0-auc:0.86400\tvalidation_1-auc:0.82848\n",
      "[26]\tvalidation_0-auc:0.86472\tvalidation_1-auc:0.82879\n",
      "[27]\tvalidation_0-auc:0.86532\tvalidation_1-auc:0.82927\n",
      "[28]\tvalidation_0-auc:0.86598\tvalidation_1-auc:0.82946\n",
      "[29]\tvalidation_0-auc:0.86666\tvalidation_1-auc:0.83019\n",
      "[30]\tvalidation_0-auc:0.86741\tvalidation_1-auc:0.83112\n",
      "[31]\tvalidation_0-auc:0.86805\tvalidation_1-auc:0.83138\n",
      "[32]\tvalidation_0-auc:0.86854\tvalidation_1-auc:0.83139\n",
      "[33]\tvalidation_0-auc:0.86912\tvalidation_1-auc:0.83163\n",
      "[34]\tvalidation_0-auc:0.86962\tvalidation_1-auc:0.83172\n",
      "[35]\tvalidation_0-auc:0.87017\tvalidation_1-auc:0.83175\n",
      "[36]\tvalidation_0-auc:0.87049\tvalidation_1-auc:0.83170\n",
      "[37]\tvalidation_0-auc:0.87123\tvalidation_1-auc:0.83140\n",
      "[38]\tvalidation_0-auc:0.87213\tvalidation_1-auc:0.83194\n",
      "[39]\tvalidation_0-auc:0.87246\tvalidation_1-auc:0.83175\n",
      "[40]\tvalidation_0-auc:0.87333\tvalidation_1-auc:0.83193\n",
      "[41]\tvalidation_0-auc:0.87420\tvalidation_1-auc:0.83173\n",
      "[42]\tvalidation_0-auc:0.87491\tvalidation_1-auc:0.83183\n",
      "[43]\tvalidation_0-auc:0.87562\tvalidation_1-auc:0.83177\n",
      "[44]\tvalidation_0-auc:0.87626\tvalidation_1-auc:0.83167\n",
      "[45]\tvalidation_0-auc:0.87685\tvalidation_1-auc:0.83159\n",
      "[46]\tvalidation_0-auc:0.87738\tvalidation_1-auc:0.83169\n",
      "[47]\tvalidation_0-auc:0.87786\tvalidation_1-auc:0.83171\n",
      "[48]\tvalidation_0-auc:0.87836\tvalidation_1-auc:0.83191\n",
      "[49]\tvalidation_0-auc:0.87884\tvalidation_1-auc:0.83202\n",
      "[50]\tvalidation_0-auc:0.87921\tvalidation_1-auc:0.83198\n",
      "[51]\tvalidation_0-auc:0.87959\tvalidation_1-auc:0.83205\n",
      "[52]\tvalidation_0-auc:0.88026\tvalidation_1-auc:0.83196\n",
      "[53]\tvalidation_0-auc:0.88058\tvalidation_1-auc:0.83214\n",
      "[54]\tvalidation_0-auc:0.88108\tvalidation_1-auc:0.83239\n",
      "[55]\tvalidation_0-auc:0.88148\tvalidation_1-auc:0.83224\n",
      "[56]\tvalidation_0-auc:0.88196\tvalidation_1-auc:0.83217\n",
      "[57]\tvalidation_0-auc:0.88231\tvalidation_1-auc:0.83215\n",
      "[58]\tvalidation_0-auc:0.88260\tvalidation_1-auc:0.83218\n",
      "[59]\tvalidation_0-auc:0.88312\tvalidation_1-auc:0.83217\n",
      "[60]\tvalidation_0-auc:0.88351\tvalidation_1-auc:0.83220\n",
      "[61]\tvalidation_0-auc:0.88431\tvalidation_1-auc:0.83262\n",
      "[62]\tvalidation_0-auc:0.88476\tvalidation_1-auc:0.83277\n",
      "[63]\tvalidation_0-auc:0.88522\tvalidation_1-auc:0.83285\n",
      "[64]\tvalidation_0-auc:0.88577\tvalidation_1-auc:0.83331\n",
      "[65]\tvalidation_0-auc:0.88609\tvalidation_1-auc:0.83328\n",
      "[66]\tvalidation_0-auc:0.88672\tvalidation_1-auc:0.83311\n",
      "[67]\tvalidation_0-auc:0.88710\tvalidation_1-auc:0.83324\n",
      "[68]\tvalidation_0-auc:0.88743\tvalidation_1-auc:0.83308\n",
      "[69]\tvalidation_0-auc:0.88786\tvalidation_1-auc:0.83300\n",
      "[70]\tvalidation_0-auc:0.88817\tvalidation_1-auc:0.83301\n",
      "[71]\tvalidation_0-auc:0.88847\tvalidation_1-auc:0.83318\n",
      "[72]\tvalidation_0-auc:0.88880\tvalidation_1-auc:0.83316\n",
      "[73]\tvalidation_0-auc:0.88899\tvalidation_1-auc:0.83318\n",
      "[74]\tvalidation_0-auc:0.88940\tvalidation_1-auc:0.83319\n",
      "[75]\tvalidation_0-auc:0.88959\tvalidation_1-auc:0.83319\n",
      "[76]\tvalidation_0-auc:0.88986\tvalidation_1-auc:0.83325\n",
      "[77]\tvalidation_0-auc:0.89028\tvalidation_1-auc:0.83326\n",
      "[78]\tvalidation_0-auc:0.89064\tvalidation_1-auc:0.83335\n",
      "[79]\tvalidation_0-auc:0.89094\tvalidation_1-auc:0.83354\n",
      "[80]\tvalidation_0-auc:0.89121\tvalidation_1-auc:0.83350\n",
      "[81]\tvalidation_0-auc:0.89143\tvalidation_1-auc:0.83346\n",
      "[82]\tvalidation_0-auc:0.89164\tvalidation_1-auc:0.83340\n",
      "[83]\tvalidation_0-auc:0.89184\tvalidation_1-auc:0.83348\n",
      "[84]\tvalidation_0-auc:0.89226\tvalidation_1-auc:0.83346\n",
      "[85]\tvalidation_0-auc:0.89254\tvalidation_1-auc:0.83351\n",
      "[86]\tvalidation_0-auc:0.89269\tvalidation_1-auc:0.83340\n",
      "[87]\tvalidation_0-auc:0.89287\tvalidation_1-auc:0.83327\n",
      "[88]\tvalidation_0-auc:0.89306\tvalidation_1-auc:0.83341\n",
      "[89]\tvalidation_0-auc:0.89342\tvalidation_1-auc:0.83344\n",
      "[90]\tvalidation_0-auc:0.89376\tvalidation_1-auc:0.83341\n",
      "[91]\tvalidation_0-auc:0.89394\tvalidation_1-auc:0.83343\n",
      "[92]\tvalidation_0-auc:0.89404\tvalidation_1-auc:0.83346\n",
      "[93]\tvalidation_0-auc:0.89441\tvalidation_1-auc:0.83345\n",
      "[94]\tvalidation_0-auc:0.89516\tvalidation_1-auc:0.83338\n",
      "[95]\tvalidation_0-auc:0.89541\tvalidation_1-auc:0.83343\n",
      "[96]\tvalidation_0-auc:0.89558\tvalidation_1-auc:0.83340\n",
      "[97]\tvalidation_0-auc:0.89599\tvalidation_1-auc:0.83343\n",
      "[98]\tvalidation_0-auc:0.89638\tvalidation_1-auc:0.83353\n",
      "[99]\tvalidation_0-auc:0.89662\tvalidation_1-auc:0.83360\n",
      "[100]\tvalidation_0-auc:0.89713\tvalidation_1-auc:0.83348\n",
      "[101]\tvalidation_0-auc:0.89719\tvalidation_1-auc:0.83352\n",
      "[102]\tvalidation_0-auc:0.89762\tvalidation_1-auc:0.83348\n",
      "[103]\tvalidation_0-auc:0.89784\tvalidation_1-auc:0.83349\n",
      "[104]\tvalidation_0-auc:0.89794\tvalidation_1-auc:0.83350\n",
      "[105]\tvalidation_0-auc:0.89828\tvalidation_1-auc:0.83358\n",
      "[106]\tvalidation_0-auc:0.89854\tvalidation_1-auc:0.83362\n",
      "[107]\tvalidation_0-auc:0.89861\tvalidation_1-auc:0.83365\n",
      "[108]\tvalidation_0-auc:0.89864\tvalidation_1-auc:0.83371\n",
      "[109]\tvalidation_0-auc:0.89874\tvalidation_1-auc:0.83371\n",
      "[110]\tvalidation_0-auc:0.89898\tvalidation_1-auc:0.83373\n",
      "[111]\tvalidation_0-auc:0.89901\tvalidation_1-auc:0.83372\n",
      "[112]\tvalidation_0-auc:0.89913\tvalidation_1-auc:0.83391\n",
      "[113]\tvalidation_0-auc:0.89916\tvalidation_1-auc:0.83392\n",
      "[114]\tvalidation_0-auc:0.89931\tvalidation_1-auc:0.83385\n",
      "[115]\tvalidation_0-auc:0.89948\tvalidation_1-auc:0.83374\n",
      "[116]\tvalidation_0-auc:0.89954\tvalidation_1-auc:0.83376\n",
      "[117]\tvalidation_0-auc:0.89973\tvalidation_1-auc:0.83372\n",
      "[118]\tvalidation_0-auc:0.89979\tvalidation_1-auc:0.83374\n",
      "[119]\tvalidation_0-auc:0.89996\tvalidation_1-auc:0.83370\n",
      "[120]\tvalidation_0-auc:0.90004\tvalidation_1-auc:0.83373\n",
      "[121]\tvalidation_0-auc:0.90039\tvalidation_1-auc:0.83373\n",
      "[122]\tvalidation_0-auc:0.90042\tvalidation_1-auc:0.83370\n",
      "[123]\tvalidation_0-auc:0.90048\tvalidation_1-auc:0.83368\n",
      "[124]\tvalidation_0-auc:0.90051\tvalidation_1-auc:0.83372\n",
      "[125]\tvalidation_0-auc:0.90067\tvalidation_1-auc:0.83372\n",
      "[126]\tvalidation_0-auc:0.90070\tvalidation_1-auc:0.83373\n",
      "[127]\tvalidation_0-auc:0.90085\tvalidation_1-auc:0.83365\n",
      "[128]\tvalidation_0-auc:0.90123\tvalidation_1-auc:0.83357\n",
      "[129]\tvalidation_0-auc:0.90132\tvalidation_1-auc:0.83352\n",
      "[130]\tvalidation_0-auc:0.90138\tvalidation_1-auc:0.83353\n",
      "[131]\tvalidation_0-auc:0.90148\tvalidation_1-auc:0.83355\n",
      "[132]\tvalidation_0-auc:0.90156\tvalidation_1-auc:0.83356\n",
      "[133]\tvalidation_0-auc:0.90179\tvalidation_1-auc:0.83362\n",
      "[134]\tvalidation_0-auc:0.90187\tvalidation_1-auc:0.83359\n",
      "[135]\tvalidation_0-auc:0.90201\tvalidation_1-auc:0.83354\n",
      "[136]\tvalidation_0-auc:0.90203\tvalidation_1-auc:0.83350\n",
      "[137]\tvalidation_0-auc:0.90205\tvalidation_1-auc:0.83354\n",
      "[138]\tvalidation_0-auc:0.90220\tvalidation_1-auc:0.83350\n",
      "[139]\tvalidation_0-auc:0.90241\tvalidation_1-auc:0.83358\n",
      "[140]\tvalidation_0-auc:0.90257\tvalidation_1-auc:0.83369\n",
      "[141]\tvalidation_0-auc:0.90262\tvalidation_1-auc:0.83369\n",
      "[142]\tvalidation_0-auc:0.90291\tvalidation_1-auc:0.83359\n",
      "[143]\tvalidation_0-auc:0.90297\tvalidation_1-auc:0.83356\n",
      "[144]\tvalidation_0-auc:0.90309\tvalidation_1-auc:0.83357\n",
      "[145]\tvalidation_0-auc:0.90317\tvalidation_1-auc:0.83351\n",
      "[146]\tvalidation_0-auc:0.90337\tvalidation_1-auc:0.83354\n",
      "[147]\tvalidation_0-auc:0.90358\tvalidation_1-auc:0.83355\n",
      "[148]\tvalidation_0-auc:0.90375\tvalidation_1-auc:0.83346\n",
      "[149]\tvalidation_0-auc:0.90377\tvalidation_1-auc:0.83346\n",
      "[150]\tvalidation_0-auc:0.90383\tvalidation_1-auc:0.83338\n",
      "[151]\tvalidation_0-auc:0.90397\tvalidation_1-auc:0.83334\n",
      "[152]\tvalidation_0-auc:0.90402\tvalidation_1-auc:0.83337\n",
      "[153]\tvalidation_0-auc:0.90404\tvalidation_1-auc:0.83333\n",
      "[154]\tvalidation_0-auc:0.90419\tvalidation_1-auc:0.83327\n",
      "[155]\tvalidation_0-auc:0.90455\tvalidation_1-auc:0.83326\n",
      "[156]\tvalidation_0-auc:0.90477\tvalidation_1-auc:0.83323\n",
      "[157]\tvalidation_0-auc:0.90485\tvalidation_1-auc:0.83327\n",
      "[158]\tvalidation_0-auc:0.90513\tvalidation_1-auc:0.83334\n",
      "[159]\tvalidation_0-auc:0.90534\tvalidation_1-auc:0.83340\n",
      "[160]\tvalidation_0-auc:0.90545\tvalidation_1-auc:0.83336\n",
      "[161]\tvalidation_0-auc:0.90552\tvalidation_1-auc:0.83330\n",
      "[162]\tvalidation_0-auc:0.90557\tvalidation_1-auc:0.83320\n",
      "[163]\tvalidation_0-auc:0.90561\tvalidation_1-auc:0.83325\n",
      "[164]\tvalidation_0-auc:0.90573\tvalidation_1-auc:0.83324\n",
      "[165]\tvalidation_0-auc:0.90581\tvalidation_1-auc:0.83325\n",
      "[166]\tvalidation_0-auc:0.90609\tvalidation_1-auc:0.83333\n",
      "[167]\tvalidation_0-auc:0.90613\tvalidation_1-auc:0.83330\n",
      "[168]\tvalidation_0-auc:0.90619\tvalidation_1-auc:0.83321\n",
      "[169]\tvalidation_0-auc:0.90625\tvalidation_1-auc:0.83315\n",
      "[170]\tvalidation_0-auc:0.90638\tvalidation_1-auc:0.83314\n",
      "[171]\tvalidation_0-auc:0.90642\tvalidation_1-auc:0.83318\n",
      "[172]\tvalidation_0-auc:0.90647\tvalidation_1-auc:0.83319\n",
      "[173]\tvalidation_0-auc:0.90656\tvalidation_1-auc:0.83316\n",
      "[174]\tvalidation_0-auc:0.90678\tvalidation_1-auc:0.83328\n",
      "[175]\tvalidation_0-auc:0.90682\tvalidation_1-auc:0.83325\n",
      "[176]\tvalidation_0-auc:0.90705\tvalidation_1-auc:0.83303\n",
      "[177]\tvalidation_0-auc:0.90726\tvalidation_1-auc:0.83301\n",
      "[178]\tvalidation_0-auc:0.90732\tvalidation_1-auc:0.83292\n",
      "[179]\tvalidation_0-auc:0.90735\tvalidation_1-auc:0.83293\n",
      "[180]\tvalidation_0-auc:0.90745\tvalidation_1-auc:0.83290\n",
      "[181]\tvalidation_0-auc:0.90761\tvalidation_1-auc:0.83288\n",
      "[182]\tvalidation_0-auc:0.90779\tvalidation_1-auc:0.83284\n",
      "[183]\tvalidation_0-auc:0.90782\tvalidation_1-auc:0.83288\n",
      "[184]\tvalidation_0-auc:0.90783\tvalidation_1-auc:0.83286\n",
      "[185]\tvalidation_0-auc:0.90791\tvalidation_1-auc:0.83284\n",
      "[186]\tvalidation_0-auc:0.90795\tvalidation_1-auc:0.83284\n",
      "[187]\tvalidation_0-auc:0.90810\tvalidation_1-auc:0.83286\n",
      "[188]\tvalidation_0-auc:0.90820\tvalidation_1-auc:0.83283\n",
      "[189]\tvalidation_0-auc:0.90823\tvalidation_1-auc:0.83281\n",
      "[190]\tvalidation_0-auc:0.90827\tvalidation_1-auc:0.83275\n",
      "[191]\tvalidation_0-auc:0.90837\tvalidation_1-auc:0.83277\n",
      "[192]\tvalidation_0-auc:0.90844\tvalidation_1-auc:0.83282\n",
      "[193]\tvalidation_0-auc:0.90868\tvalidation_1-auc:0.83276\n",
      "[194]\tvalidation_0-auc:0.90870\tvalidation_1-auc:0.83279\n",
      "[195]\tvalidation_0-auc:0.90877\tvalidation_1-auc:0.83275\n",
      "[196]\tvalidation_0-auc:0.90881\tvalidation_1-auc:0.83282\n",
      "[197]\tvalidation_0-auc:0.90893\tvalidation_1-auc:0.83282\n",
      "[198]\tvalidation_0-auc:0.90919\tvalidation_1-auc:0.83272\n",
      "[199]\tvalidation_0-auc:0.90923\tvalidation_1-auc:0.83269\n",
      "[200]\tvalidation_0-auc:0.90933\tvalidation_1-auc:0.83270\n",
      "[201]\tvalidation_0-auc:0.90948\tvalidation_1-auc:0.83266\n",
      "[202]\tvalidation_0-auc:0.90951\tvalidation_1-auc:0.83268\n",
      "[203]\tvalidation_0-auc:0.90953\tvalidation_1-auc:0.83267\n",
      "[204]\tvalidation_0-auc:0.90975\tvalidation_1-auc:0.83268\n",
      "[205]\tvalidation_0-auc:0.90997\tvalidation_1-auc:0.83257\n",
      "[206]\tvalidation_0-auc:0.91005\tvalidation_1-auc:0.83253\n",
      "[207]\tvalidation_0-auc:0.91028\tvalidation_1-auc:0.83256\n",
      "[208]\tvalidation_0-auc:0.91031\tvalidation_1-auc:0.83261\n",
      "[209]\tvalidation_0-auc:0.91048\tvalidation_1-auc:0.83259\n",
      "[210]\tvalidation_0-auc:0.91050\tvalidation_1-auc:0.83261\n",
      "[211]\tvalidation_0-auc:0.91055\tvalidation_1-auc:0.83255\n",
      "[212]\tvalidation_0-auc:0.91060\tvalidation_1-auc:0.83249\n",
      "[213]\tvalidation_0-auc:0.91088\tvalidation_1-auc:0.83242\n",
      "ROC AUC: 0.8417\n"
     ]
    }
   ],
   "source": [
    "#XGBoost 모델 학습과 하이퍼 파라미터 튜닝\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#클래스 생성\n",
    "xgb_clf=XGBClassifier(n_estimators=500,learning_rate=0.05,random_state=156)\n",
    "\n",
    "#fit\n",
    "xgb_clf.fit(X_tr,y_tr,early_stopping_rounds=100,eval_metric='auc',eval_set=[(X_tr,y_tr),(X_val,y_val)])\n",
    "\n",
    "#predic한거 auc점수\n",
    "xgb_roc_score=roc_auc_score(y_test,xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (1.11.4)\n",
      "Requirement already satisfied: six in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (3.2.1)\n",
      "Requirement already satisfied: future in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (4.66.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (3.0.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->hyperopt) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#XGBoost 하이퍼파라미터 튜닝 by HyperOpt\n",
    "\n",
    "!pip install hyperopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost 하이퍼 파라미터 튜닝\n",
    "#hp.uniform: 정의된 범위 내에서 임의의 숫자를 무작위 추출\n",
    "# hp.quniform: 정의된 범위 내에서 마지막 숫자만큼의 간격을 두어 숫자를 추출 \n",
    "from hyperopt import hp\n",
    "\n",
    "xgb_search_space = {'max_depth': hp.quniform( 'max_depth' , 5, 15, 1), \n",
    "'min_child_weight' : hp.quniform( 'min_child_weight' , 1, 6, 1), \n",
    "'colsample_bytree' : hp.uniform( 'colsample_bytree' , 0.5, 0.95), \n",
    "'learning_rate' : hp.uniform( 'learning_rate' ,0.01 , 0.2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def objective_func(search_space):\n",
    "    xgb_clf=XGBClassifier(n_estimators=30,max_depth=int(search_space['max_depth']),\n",
    "                          min_child_weight=int(search_space['min_child_weight']),\n",
    "                          colsample_bytree=search_space['colsample_bytree'],\n",
    "                          learning_rate=search_space['learning_rate'])\n",
    "    \n",
    "    roc_auc_list=[]\n",
    "    \n",
    "    #3개의 k-fold 방식 적용\n",
    "    kf=KFold(n_splits=3)\n",
    "    #X_train -> 학습 / 검증용 데이터 분리\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        X_tr,y_tr=X_train.iloc[tr_index],y_train.iloc[tr_index]\n",
    "        X_val,y_val=X_train.iloc[val_index],y_train.iloc[val_index]\n",
    "        \n",
    "        #추출된 학습 / 검증 데이터로 XGBClassifier 학습 수행\n",
    "        xgb_clf.fit(X_tr,y_tr,early_stopping_rounds=10,eval_metric='auc',\n",
    "                    eval_set=[(X_tr,y_tr),(X_val,y_val)])\n",
    "        \n",
    "        score=roc_auc_score(y_val,xgb_clf.predict_proba(X_val)[:,1])\n",
    "        roc_auc_list.append(score)\n",
    "        \n",
    "        #3개의 k-fold로 계산된 roc-auc값의 평균값 반한하되, -1 곱하기 \n",
    "        #HyperOpt는 목적함수의 최솟값을 위한 입력값을 찾기 때문\n",
    "        return -1*np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.76925\tvalidation_1-auc:0.73368 \n",
      "[1]\tvalidation_0-auc:0.77931\tvalidation_1-auc:0.74099 \n",
      "[2]\tvalidation_0-auc:0.78206\tvalidation_1-auc:0.74516 \n",
      "[3]\tvalidation_0-auc:0.82632\tvalidation_1-auc:0.79329 \n",
      "[4]\tvalidation_0-auc:0.82410\tvalidation_1-auc:0.79134 \n",
      "[5]\tvalidation_0-auc:0.83679\tvalidation_1-auc:0.80348 \n",
      "[6]\tvalidation_0-auc:0.84272\tvalidation_1-auc:0.80982 \n",
      "[7]\tvalidation_0-auc:0.84774\tvalidation_1-auc:0.81687 \n",
      "[8]\tvalidation_0-auc:0.84653\tvalidation_1-auc:0.81238 \n",
      "[9]\tvalidation_0-auc:0.85115\tvalidation_1-auc:0.81855 \n",
      "[10]\tvalidation_0-auc:0.85084\tvalidation_1-auc:0.81767\n",
      "[11]\tvalidation_0-auc:0.85443\tvalidation_1-auc:0.82027\n",
      "[12]\tvalidation_0-auc:0.85277\tvalidation_1-auc:0.81820\n",
      "[13]\tvalidation_0-auc:0.85278\tvalidation_1-auc:0.81682\n",
      "[14]\tvalidation_0-auc:0.85604\tvalidation_1-auc:0.82069\n",
      "[15]\tvalidation_0-auc:0.85590\tvalidation_1-auc:0.81956\n",
      "[16]\tvalidation_0-auc:0.85906\tvalidation_1-auc:0.82247\n",
      "[17]\tvalidation_0-auc:0.85852\tvalidation_1-auc:0.82120\n",
      "[18]\tvalidation_0-auc:0.86150\tvalidation_1-auc:0.82497\n",
      "[19]\tvalidation_0-auc:0.86325\tvalidation_1-auc:0.82700\n",
      "[20]\tvalidation_0-auc:0.86564\tvalidation_1-auc:0.82877\n",
      "[21]\tvalidation_0-auc:0.86539\tvalidation_1-auc:0.82758\n",
      "[22]\tvalidation_0-auc:0.86756\tvalidation_1-auc:0.82920\n",
      "[23]\tvalidation_0-auc:0.86735\tvalidation_1-auc:0.82831\n",
      "[24]\tvalidation_0-auc:0.86883\tvalidation_1-auc:0.82944\n",
      "[25]\tvalidation_0-auc:0.87003\tvalidation_1-auc:0.83050\n",
      "[26]\tvalidation_0-auc:0.87133\tvalidation_1-auc:0.83189\n",
      "[27]\tvalidation_0-auc:0.87245\tvalidation_1-auc:0.83363\n",
      "[28]\tvalidation_0-auc:0.87314\tvalidation_1-auc:0.83343\n",
      "[29]\tvalidation_0-auc:0.87420\tvalidation_1-auc:0.83290\n",
      "[0]\tvalidation_0-auc:0.80191\tvalidation_1-auc:0.73827                           \n",
      "[1]\tvalidation_0-auc:0.81826\tvalidation_1-auc:0.74570                           \n",
      "[2]\tvalidation_0-auc:0.81989\tvalidation_1-auc:0.74970                           \n",
      "[3]\tvalidation_0-auc:0.86182\tvalidation_1-auc:0.79325                           \n",
      "[4]\tvalidation_0-auc:0.85845\tvalidation_1-auc:0.79264                           \n",
      "[5]\tvalidation_0-auc:0.86574\tvalidation_1-auc:0.80410                           \n",
      "[6]\tvalidation_0-auc:0.86890\tvalidation_1-auc:0.81144                           \n",
      "[7]\tvalidation_0-auc:0.86768\tvalidation_1-auc:0.80887                           \n",
      "[8]\tvalidation_0-auc:0.86838\tvalidation_1-auc:0.80742                           \n",
      "[9]\tvalidation_0-auc:0.87337\tvalidation_1-auc:0.81111                           \n",
      "[10]\tvalidation_0-auc:0.87329\tvalidation_1-auc:0.80805                          \n",
      "[11]\tvalidation_0-auc:0.87919\tvalidation_1-auc:0.81238                          \n",
      "[12]\tvalidation_0-auc:0.87876\tvalidation_1-auc:0.81092                          \n",
      "[13]\tvalidation_0-auc:0.87922\tvalidation_1-auc:0.81008                          \n",
      "[14]\tvalidation_0-auc:0.87876\tvalidation_1-auc:0.81048                          \n",
      "[15]\tvalidation_0-auc:0.87747\tvalidation_1-auc:0.80863                          \n",
      "[16]\tvalidation_0-auc:0.87799\tvalidation_1-auc:0.80801                          \n",
      "[17]\tvalidation_0-auc:0.87786\tvalidation_1-auc:0.80719                          \n",
      "[18]\tvalidation_0-auc:0.88167\tvalidation_1-auc:0.81133                          \n",
      "[19]\tvalidation_0-auc:0.88478\tvalidation_1-auc:0.81411                          \n",
      "[20]\tvalidation_0-auc:0.88722\tvalidation_1-auc:0.81657                          \n",
      "[21]\tvalidation_0-auc:0.88643\tvalidation_1-auc:0.81457                          \n",
      "[22]\tvalidation_0-auc:0.88696\tvalidation_1-auc:0.81425                          \n",
      "[23]\tvalidation_0-auc:0.88749\tvalidation_1-auc:0.81369                          \n",
      "[24]\tvalidation_0-auc:0.89014\tvalidation_1-auc:0.81615                          \n",
      "[25]\tvalidation_0-auc:0.89139\tvalidation_1-auc:0.81843                          \n",
      "[26]\tvalidation_0-auc:0.89155\tvalidation_1-auc:0.81795                          \n",
      "[27]\tvalidation_0-auc:0.89386\tvalidation_1-auc:0.81926                          \n",
      "[28]\tvalidation_0-auc:0.89444\tvalidation_1-auc:0.81930                          \n",
      "[29]\tvalidation_0-auc:0.89424\tvalidation_1-auc:0.81880                          \n",
      "[0]\tvalidation_0-auc:0.80314\tvalidation_1-auc:0.73376                           \n",
      "[1]\tvalidation_0-auc:0.81780\tvalidation_1-auc:0.74015                           \n",
      "[2]\tvalidation_0-auc:0.82340\tvalidation_1-auc:0.74562                           \n",
      "[3]\tvalidation_0-auc:0.86762\tvalidation_1-auc:0.78965                           \n",
      "[4]\tvalidation_0-auc:0.86862\tvalidation_1-auc:0.78867                           \n",
      "[5]\tvalidation_0-auc:0.87882\tvalidation_1-auc:0.80355                           \n",
      "[6]\tvalidation_0-auc:0.88441\tvalidation_1-auc:0.81078                           \n",
      "[7]\tvalidation_0-auc:0.88884\tvalidation_1-auc:0.81542                           \n",
      "[8]\tvalidation_0-auc:0.89075\tvalidation_1-auc:0.81256                           \n",
      "[9]\tvalidation_0-auc:0.89598\tvalidation_1-auc:0.81787                           \n",
      "[10]\tvalidation_0-auc:0.89724\tvalidation_1-auc:0.81423                          \n",
      "[11]\tvalidation_0-auc:0.90355\tvalidation_1-auc:0.81870                          \n",
      "[12]\tvalidation_0-auc:0.90348\tvalidation_1-auc:0.81703                          \n",
      "[13]\tvalidation_0-auc:0.90425\tvalidation_1-auc:0.81526                          \n",
      "[14]\tvalidation_0-auc:0.90886\tvalidation_1-auc:0.81826                          \n",
      "[15]\tvalidation_0-auc:0.90925\tvalidation_1-auc:0.81606                          \n",
      "[16]\tvalidation_0-auc:0.91314\tvalidation_1-auc:0.81823                          \n",
      "[17]\tvalidation_0-auc:0.91377\tvalidation_1-auc:0.81762                          \n",
      "[18]\tvalidation_0-auc:0.91654\tvalidation_1-auc:0.82142                          \n",
      "[19]\tvalidation_0-auc:0.91872\tvalidation_1-auc:0.82252                          \n",
      "[20]\tvalidation_0-auc:0.92031\tvalidation_1-auc:0.82353                          \n",
      "[21]\tvalidation_0-auc:0.92085\tvalidation_1-auc:0.82230                          \n",
      "[22]\tvalidation_0-auc:0.92299\tvalidation_1-auc:0.82319                          \n",
      "[23]\tvalidation_0-auc:0.92393\tvalidation_1-auc:0.82289                          \n",
      "[24]\tvalidation_0-auc:0.92566\tvalidation_1-auc:0.82328                          \n",
      "[25]\tvalidation_0-auc:0.92696\tvalidation_1-auc:0.82460                          \n",
      "[26]\tvalidation_0-auc:0.92802\tvalidation_1-auc:0.82543                          \n",
      "[27]\tvalidation_0-auc:0.92938\tvalidation_1-auc:0.82555                          \n",
      "[28]\tvalidation_0-auc:0.92966\tvalidation_1-auc:0.82572                          \n",
      "[29]\tvalidation_0-auc:0.92992\tvalidation_1-auc:0.82550                          \n",
      "[0]\tvalidation_0-auc:0.80565\tvalidation_1-auc:0.73369                           \n",
      "[1]\tvalidation_0-auc:0.82144\tvalidation_1-auc:0.74535                           \n",
      "[2]\tvalidation_0-auc:0.82337\tvalidation_1-auc:0.74974                           \n",
      "[3]\tvalidation_0-auc:0.86607\tvalidation_1-auc:0.79034                           \n",
      "[4]\tvalidation_0-auc:0.86242\tvalidation_1-auc:0.78678                           \n",
      "[5]\tvalidation_0-auc:0.86908\tvalidation_1-auc:0.80086                           \n",
      "[6]\tvalidation_0-auc:0.87232\tvalidation_1-auc:0.80696                           \n",
      "[7]\tvalidation_0-auc:0.87119\tvalidation_1-auc:0.80417                           \n",
      "[8]\tvalidation_0-auc:0.87185\tvalidation_1-auc:0.80405                           \n",
      "[9]\tvalidation_0-auc:0.87743\tvalidation_1-auc:0.80845                           \n",
      "[10]\tvalidation_0-auc:0.87646\tvalidation_1-auc:0.80652                          \n",
      "[11]\tvalidation_0-auc:0.88133\tvalidation_1-auc:0.81070                          \n",
      "[12]\tvalidation_0-auc:0.88058\tvalidation_1-auc:0.80907                          \n",
      "[13]\tvalidation_0-auc:0.88088\tvalidation_1-auc:0.80739                          \n",
      "[14]\tvalidation_0-auc:0.88126\tvalidation_1-auc:0.80682                          \n",
      "[15]\tvalidation_0-auc:0.88016\tvalidation_1-auc:0.80508                          \n",
      "[16]\tvalidation_0-auc:0.88312\tvalidation_1-auc:0.80789                          \n",
      "[17]\tvalidation_0-auc:0.88304\tvalidation_1-auc:0.80649                          \n",
      "[18]\tvalidation_0-auc:0.88589\tvalidation_1-auc:0.81009                          \n",
      "[19]\tvalidation_0-auc:0.88846\tvalidation_1-auc:0.81211                          \n",
      "[20]\tvalidation_0-auc:0.89099\tvalidation_1-auc:0.81434                          \n",
      "[21]\tvalidation_0-auc:0.89039\tvalidation_1-auc:0.81313                          \n",
      "[22]\tvalidation_0-auc:0.89309\tvalidation_1-auc:0.81480                          \n",
      "[23]\tvalidation_0-auc:0.89309\tvalidation_1-auc:0.81419                          \n",
      "[24]\tvalidation_0-auc:0.89525\tvalidation_1-auc:0.81592                          \n",
      "[25]\tvalidation_0-auc:0.89649\tvalidation_1-auc:0.81705                          \n",
      "[26]\tvalidation_0-auc:0.89778\tvalidation_1-auc:0.81835                          \n",
      "[27]\tvalidation_0-auc:0.89951\tvalidation_1-auc:0.82040                          \n",
      "[28]\tvalidation_0-auc:0.90002\tvalidation_1-auc:0.82012                          \n",
      "[29]\tvalidation_0-auc:0.89967\tvalidation_1-auc:0.81935                          \n",
      "[0]\tvalidation_0-auc:0.81019\tvalidation_1-auc:0.72891                           \n",
      "[1]\tvalidation_0-auc:0.82386\tvalidation_1-auc:0.73253                           \n",
      "[2]\tvalidation_0-auc:0.83972\tvalidation_1-auc:0.74245                           \n",
      "[3]\tvalidation_0-auc:0.87697\tvalidation_1-auc:0.78528                           \n",
      "[4]\tvalidation_0-auc:0.87965\tvalidation_1-auc:0.78727                           \n",
      "[5]\tvalidation_0-auc:0.88967\tvalidation_1-auc:0.80566                           \n",
      "[6]\tvalidation_0-auc:0.89631\tvalidation_1-auc:0.81182                           \n",
      "[7]\tvalidation_0-auc:0.90064\tvalidation_1-auc:0.81604                           \n",
      "[8]\tvalidation_0-auc:0.90326\tvalidation_1-auc:0.81335                           \n",
      "[9]\tvalidation_0-auc:0.91091\tvalidation_1-auc:0.81682                           \n",
      "[10]\tvalidation_0-auc:0.91210\tvalidation_1-auc:0.81360                          \n",
      "[11]\tvalidation_0-auc:0.91708\tvalidation_1-auc:0.81754                          \n",
      "[12]\tvalidation_0-auc:0.91764\tvalidation_1-auc:0.81488                          \n",
      "[13]\tvalidation_0-auc:0.91848\tvalidation_1-auc:0.81357                          \n",
      "[14]\tvalidation_0-auc:0.92298\tvalidation_1-auc:0.81806                          \n",
      "[15]\tvalidation_0-auc:0.92668\tvalidation_1-auc:0.81991                          \n",
      "[16]\tvalidation_0-auc:0.92935\tvalidation_1-auc:0.82197                          \n",
      "[17]\tvalidation_0-auc:0.93069\tvalidation_1-auc:0.82172                          \n",
      "[18]\tvalidation_0-auc:0.93165\tvalidation_1-auc:0.82281                          \n",
      "[19]\tvalidation_0-auc:0.93349\tvalidation_1-auc:0.82359                          \n",
      "[20]\tvalidation_0-auc:0.93482\tvalidation_1-auc:0.82395                          \n",
      "[21]\tvalidation_0-auc:0.93570\tvalidation_1-auc:0.82317                          \n",
      "[22]\tvalidation_0-auc:0.93657\tvalidation_1-auc:0.82405                          \n",
      "[23]\tvalidation_0-auc:0.93777\tvalidation_1-auc:0.82324                          \n",
      "[24]\tvalidation_0-auc:0.93898\tvalidation_1-auc:0.82235                          \n",
      "[25]\tvalidation_0-auc:0.94061\tvalidation_1-auc:0.82242                          \n",
      "[26]\tvalidation_0-auc:0.94139\tvalidation_1-auc:0.82341                          \n",
      "[27]\tvalidation_0-auc:0.94195\tvalidation_1-auc:0.82338                          \n",
      "[28]\tvalidation_0-auc:0.94229\tvalidation_1-auc:0.82324                          \n",
      "[29]\tvalidation_0-auc:0.94281\tvalidation_1-auc:0.82296                          \n",
      "[0]\tvalidation_0-auc:0.78499\tvalidation_1-auc:0.73550                           \n",
      "[1]\tvalidation_0-auc:0.79232\tvalidation_1-auc:0.75088                           \n",
      "[2]\tvalidation_0-auc:0.79420\tvalidation_1-auc:0.75893                           \n",
      "[3]\tvalidation_0-auc:0.83927\tvalidation_1-auc:0.80064                           \n",
      "[4]\tvalidation_0-auc:0.83610\tvalidation_1-auc:0.79622                           \n",
      "[5]\tvalidation_0-auc:0.84640\tvalidation_1-auc:0.80494                           \n",
      "[6]\tvalidation_0-auc:0.85170\tvalidation_1-auc:0.81237                           \n",
      "[7]\tvalidation_0-auc:0.85645\tvalidation_1-auc:0.81842                           \n",
      "[8]\tvalidation_0-auc:0.85562\tvalidation_1-auc:0.81494                           \n",
      "[9]\tvalidation_0-auc:0.85959\tvalidation_1-auc:0.82007                           \n",
      "[10]\tvalidation_0-auc:0.85876\tvalidation_1-auc:0.81653                          \n",
      "[11]\tvalidation_0-auc:0.86209\tvalidation_1-auc:0.81999                          \n",
      "[12]\tvalidation_0-auc:0.86089\tvalidation_1-auc:0.81807                          \n",
      "[13]\tvalidation_0-auc:0.86093\tvalidation_1-auc:0.81534                          \n",
      "[14]\tvalidation_0-auc:0.86459\tvalidation_1-auc:0.81988                          \n",
      "[15]\tvalidation_0-auc:0.86426\tvalidation_1-auc:0.81780                          \n",
      "[16]\tvalidation_0-auc:0.86699\tvalidation_1-auc:0.82137                          \n",
      "[17]\tvalidation_0-auc:0.86684\tvalidation_1-auc:0.81906                          \n",
      "[18]\tvalidation_0-auc:0.86886\tvalidation_1-auc:0.82286                          \n",
      "[19]\tvalidation_0-auc:0.87123\tvalidation_1-auc:0.82548                          \n",
      "[20]\tvalidation_0-auc:0.87388\tvalidation_1-auc:0.82669                          \n",
      "[21]\tvalidation_0-auc:0.87312\tvalidation_1-auc:0.82580                          \n",
      "[22]\tvalidation_0-auc:0.87556\tvalidation_1-auc:0.82740                          \n",
      "[23]\tvalidation_0-auc:0.87598\tvalidation_1-auc:0.82708                          \n",
      "[24]\tvalidation_0-auc:0.87840\tvalidation_1-auc:0.82846                          \n",
      "[25]\tvalidation_0-auc:0.88017\tvalidation_1-auc:0.82982                          \n",
      "[26]\tvalidation_0-auc:0.88164\tvalidation_1-auc:0.83106                          \n",
      "[27]\tvalidation_0-auc:0.88283\tvalidation_1-auc:0.83195                          \n",
      "[28]\tvalidation_0-auc:0.88335\tvalidation_1-auc:0.83140                          \n",
      "[29]\tvalidation_0-auc:0.88367\tvalidation_1-auc:0.83092                          \n",
      "[0]\tvalidation_0-auc:0.78083\tvalidation_1-auc:0.73136                           \n",
      "[1]\tvalidation_0-auc:0.79324\tvalidation_1-auc:0.75641                           \n",
      "[2]\tvalidation_0-auc:0.79683\tvalidation_1-auc:0.75771                           \n",
      "[3]\tvalidation_0-auc:0.84234\tvalidation_1-auc:0.80130                           \n",
      "[4]\tvalidation_0-auc:0.83863\tvalidation_1-auc:0.79616                           \n",
      "[5]\tvalidation_0-auc:0.84862\tvalidation_1-auc:0.80688                           \n",
      "[6]\tvalidation_0-auc:0.85402\tvalidation_1-auc:0.81453                           \n",
      "[7]\tvalidation_0-auc:0.85183\tvalidation_1-auc:0.81070                           \n",
      "[8]\tvalidation_0-auc:0.85292\tvalidation_1-auc:0.80902                           \n",
      "[9]\tvalidation_0-auc:0.85864\tvalidation_1-auc:0.81410                           \n",
      "[10]\tvalidation_0-auc:0.85797\tvalidation_1-auc:0.81047                          \n",
      "[11]\tvalidation_0-auc:0.86291\tvalidation_1-auc:0.81630                          \n",
      "[12]\tvalidation_0-auc:0.86149\tvalidation_1-auc:0.81390                          \n",
      "[13]\tvalidation_0-auc:0.86249\tvalidation_1-auc:0.81390                          \n",
      "[14]\tvalidation_0-auc:0.86281\tvalidation_1-auc:0.81239                          \n",
      "[15]\tvalidation_0-auc:0.86291\tvalidation_1-auc:0.81083                          \n",
      "[16]\tvalidation_0-auc:0.86766\tvalidation_1-auc:0.81540                          \n",
      "[17]\tvalidation_0-auc:0.86837\tvalidation_1-auc:0.81441                          \n",
      "[18]\tvalidation_0-auc:0.87225\tvalidation_1-auc:0.81833                          \n",
      "[19]\tvalidation_0-auc:0.87537\tvalidation_1-auc:0.82205                          \n",
      "[20]\tvalidation_0-auc:0.87854\tvalidation_1-auc:0.82544                          \n",
      "[21]\tvalidation_0-auc:0.87894\tvalidation_1-auc:0.82436                          \n",
      "[22]\tvalidation_0-auc:0.88171\tvalidation_1-auc:0.82684                          \n",
      "[23]\tvalidation_0-auc:0.88186\tvalidation_1-auc:0.82589                          \n",
      "[24]\tvalidation_0-auc:0.88406\tvalidation_1-auc:0.82773                          \n",
      "[25]\tvalidation_0-auc:0.88566\tvalidation_1-auc:0.82927                          \n",
      "[26]\tvalidation_0-auc:0.88689\tvalidation_1-auc:0.83005                          \n",
      "[27]\tvalidation_0-auc:0.88828\tvalidation_1-auc:0.83131                          \n",
      "[28]\tvalidation_0-auc:0.88905\tvalidation_1-auc:0.83129                          \n",
      "[29]\tvalidation_0-auc:0.88962\tvalidation_1-auc:0.83097                          \n",
      "[0]\tvalidation_0-auc:0.81577\tvalidation_1-auc:0.72977                           \n",
      "[1]\tvalidation_0-auc:0.82487\tvalidation_1-auc:0.73981                           \n",
      "[2]\tvalidation_0-auc:0.83058\tvalidation_1-auc:0.74455                           \n",
      "[3]\tvalidation_0-auc:0.87193\tvalidation_1-auc:0.78649                           \n",
      "[4]\tvalidation_0-auc:0.86943\tvalidation_1-auc:0.78473                           \n",
      "[5]\tvalidation_0-auc:0.87874\tvalidation_1-auc:0.80043                           \n",
      "[6]\tvalidation_0-auc:0.88483\tvalidation_1-auc:0.80812                           \n",
      "[7]\tvalidation_0-auc:0.88739\tvalidation_1-auc:0.81145                           \n",
      "[8]\tvalidation_0-auc:0.88904\tvalidation_1-auc:0.80889                           \n",
      "[9]\tvalidation_0-auc:0.89375\tvalidation_1-auc:0.81313                           \n",
      "[10]\tvalidation_0-auc:0.89420\tvalidation_1-auc:0.81056                          \n",
      "[11]\tvalidation_0-auc:0.89831\tvalidation_1-auc:0.81395                          \n",
      "[12]\tvalidation_0-auc:0.89789\tvalidation_1-auc:0.81262                          \n",
      "[13]\tvalidation_0-auc:0.89778\tvalidation_1-auc:0.81149                          \n",
      "[14]\tvalidation_0-auc:0.90146\tvalidation_1-auc:0.81362                          \n",
      "[15]\tvalidation_0-auc:0.90393\tvalidation_1-auc:0.81500                          \n",
      "[16]\tvalidation_0-auc:0.90621\tvalidation_1-auc:0.81666                          \n",
      "[17]\tvalidation_0-auc:0.90655\tvalidation_1-auc:0.81600                          \n",
      "[18]\tvalidation_0-auc:0.90803\tvalidation_1-auc:0.81834                          \n",
      "[19]\tvalidation_0-auc:0.90928\tvalidation_1-auc:0.82015                          \n",
      "[20]\tvalidation_0-auc:0.91083\tvalidation_1-auc:0.82252                          \n",
      "[21]\tvalidation_0-auc:0.91070\tvalidation_1-auc:0.82166                          \n",
      "[22]\tvalidation_0-auc:0.91201\tvalidation_1-auc:0.82302                          \n",
      "[23]\tvalidation_0-auc:0.91212\tvalidation_1-auc:0.82254                          \n",
      "[24]\tvalidation_0-auc:0.91375\tvalidation_1-auc:0.82331                          \n",
      "[25]\tvalidation_0-auc:0.91523\tvalidation_1-auc:0.82357                          \n",
      "[26]\tvalidation_0-auc:0.91655\tvalidation_1-auc:0.82411                          \n",
      "[27]\tvalidation_0-auc:0.91765\tvalidation_1-auc:0.82486                          \n",
      "[28]\tvalidation_0-auc:0.91859\tvalidation_1-auc:0.82412                          \n",
      "[29]\tvalidation_0-auc:0.91899\tvalidation_1-auc:0.82325                          \n",
      "[0]\tvalidation_0-auc:0.77063\tvalidation_1-auc:0.73223                           \n",
      "[1]\tvalidation_0-auc:0.83749\tvalidation_1-auc:0.80728                           \n",
      "[2]\tvalidation_0-auc:0.82900\tvalidation_1-auc:0.79918                           \n",
      "[3]\tvalidation_0-auc:0.84265\tvalidation_1-auc:0.81131                           \n",
      "[4]\tvalidation_0-auc:0.83857\tvalidation_1-auc:0.80572                           \n",
      "[5]\tvalidation_0-auc:0.84690\tvalidation_1-auc:0.81541                           \n",
      "[6]\tvalidation_0-auc:0.85311\tvalidation_1-auc:0.82262                           \n",
      "[7]\tvalidation_0-auc:0.85529\tvalidation_1-auc:0.82450                           \n",
      "[8]\tvalidation_0-auc:0.85541\tvalidation_1-auc:0.82210                           \n",
      "[9]\tvalidation_0-auc:0.86033\tvalidation_1-auc:0.82490                           \n",
      "[10]\tvalidation_0-auc:0.86212\tvalidation_1-auc:0.82604                          \n",
      "[11]\tvalidation_0-auc:0.86528\tvalidation_1-auc:0.82789                          \n",
      "[12]\tvalidation_0-auc:0.86725\tvalidation_1-auc:0.82866                          \n",
      "[13]\tvalidation_0-auc:0.86691\tvalidation_1-auc:0.82660                          \n",
      "[14]\tvalidation_0-auc:0.86898\tvalidation_1-auc:0.82830                          \n",
      "[15]\tvalidation_0-auc:0.87019\tvalidation_1-auc:0.82848                          \n",
      "[16]\tvalidation_0-auc:0.87221\tvalidation_1-auc:0.82859                          \n",
      "[17]\tvalidation_0-auc:0.87353\tvalidation_1-auc:0.82885                          \n",
      "[18]\tvalidation_0-auc:0.87450\tvalidation_1-auc:0.82933                          \n",
      "[19]\tvalidation_0-auc:0.87599\tvalidation_1-auc:0.83053                          \n",
      "[20]\tvalidation_0-auc:0.87693\tvalidation_1-auc:0.83104                          \n",
      "[21]\tvalidation_0-auc:0.87791\tvalidation_1-auc:0.83113                          \n",
      "[22]\tvalidation_0-auc:0.87885\tvalidation_1-auc:0.83113                          \n",
      "[23]\tvalidation_0-auc:0.87995\tvalidation_1-auc:0.83123                          \n",
      "[24]\tvalidation_0-auc:0.88047\tvalidation_1-auc:0.83142                          \n",
      "[25]\tvalidation_0-auc:0.88114\tvalidation_1-auc:0.83209                          \n",
      "[26]\tvalidation_0-auc:0.88154\tvalidation_1-auc:0.83226                          \n",
      "[27]\tvalidation_0-auc:0.88188\tvalidation_1-auc:0.83259                          \n",
      "[28]\tvalidation_0-auc:0.88294\tvalidation_1-auc:0.83236                          \n",
      "[29]\tvalidation_0-auc:0.88339\tvalidation_1-auc:0.83234                          \n",
      "[0]\tvalidation_0-auc:0.81099\tvalidation_1-auc:0.72943                           \n",
      "[1]\tvalidation_0-auc:0.87503\tvalidation_1-auc:0.79943                           \n",
      "[2]\tvalidation_0-auc:0.87648\tvalidation_1-auc:0.78826                           \n",
      "[3]\tvalidation_0-auc:0.88510\tvalidation_1-auc:0.80232                           \n",
      "[4]\tvalidation_0-auc:0.88478\tvalidation_1-auc:0.80020                           \n",
      "[5]\tvalidation_0-auc:0.89431\tvalidation_1-auc:0.81128                           \n",
      "[6]\tvalidation_0-auc:0.89980\tvalidation_1-auc:0.81539                           \n",
      "[7]\tvalidation_0-auc:0.90252\tvalidation_1-auc:0.82048                           \n",
      "[8]\tvalidation_0-auc:0.90645\tvalidation_1-auc:0.82237                           \n",
      "[9]\tvalidation_0-auc:0.90895\tvalidation_1-auc:0.82504                           \n",
      "[10]\tvalidation_0-auc:0.91230\tvalidation_1-auc:0.82638                          \n",
      "[11]\tvalidation_0-auc:0.91431\tvalidation_1-auc:0.82478                          \n",
      "[12]\tvalidation_0-auc:0.91690\tvalidation_1-auc:0.82620                          \n",
      "[13]\tvalidation_0-auc:0.91981\tvalidation_1-auc:0.82449                          \n",
      "[14]\tvalidation_0-auc:0.92285\tvalidation_1-auc:0.82414                          \n",
      "[15]\tvalidation_0-auc:0.92511\tvalidation_1-auc:0.82515                          \n",
      "[16]\tvalidation_0-auc:0.92720\tvalidation_1-auc:0.82587                          \n",
      "[17]\tvalidation_0-auc:0.92842\tvalidation_1-auc:0.82643                          \n",
      "[18]\tvalidation_0-auc:0.93010\tvalidation_1-auc:0.82627                          \n",
      "[19]\tvalidation_0-auc:0.93174\tvalidation_1-auc:0.82652                          \n",
      "[20]\tvalidation_0-auc:0.93379\tvalidation_1-auc:0.82573                          \n",
      "[21]\tvalidation_0-auc:0.93472\tvalidation_1-auc:0.82581                          \n",
      "[22]\tvalidation_0-auc:0.93563\tvalidation_1-auc:0.82554                          \n",
      "[23]\tvalidation_0-auc:0.93700\tvalidation_1-auc:0.82588                          \n",
      "[24]\tvalidation_0-auc:0.93788\tvalidation_1-auc:0.82577                          \n",
      "[25]\tvalidation_0-auc:0.93863\tvalidation_1-auc:0.82583                          \n",
      "[26]\tvalidation_0-auc:0.93954\tvalidation_1-auc:0.82583                          \n",
      "[27]\tvalidation_0-auc:0.93973\tvalidation_1-auc:0.82591                          \n",
      "[28]\tvalidation_0-auc:0.94014\tvalidation_1-auc:0.82600                          \n",
      "[0]\tvalidation_0-auc:0.81960\tvalidation_1-auc:0.72050                            \n",
      "[1]\tvalidation_0-auc:0.83046\tvalidation_1-auc:0.73232                            \n",
      "[2]\tvalidation_0-auc:0.83638\tvalidation_1-auc:0.74320                            \n",
      "[3]\tvalidation_0-auc:0.87794\tvalidation_1-auc:0.78381                            \n",
      "[4]\tvalidation_0-auc:0.87683\tvalidation_1-auc:0.78254                            \n",
      "[5]\tvalidation_0-auc:0.88401\tvalidation_1-auc:0.79542                            \n",
      "[6]\tvalidation_0-auc:0.88693\tvalidation_1-auc:0.80228                            \n",
      "[7]\tvalidation_0-auc:0.88952\tvalidation_1-auc:0.80663                            \n",
      "[8]\tvalidation_0-auc:0.89247\tvalidation_1-auc:0.80402                            \n",
      "[9]\tvalidation_0-auc:0.89554\tvalidation_1-auc:0.80719                            \n",
      "[10]\tvalidation_0-auc:0.89598\tvalidation_1-auc:0.80483                           \n",
      "[11]\tvalidation_0-auc:0.89833\tvalidation_1-auc:0.80715                           \n",
      "[12]\tvalidation_0-auc:0.89753\tvalidation_1-auc:0.80573                           \n",
      "[13]\tvalidation_0-auc:0.89815\tvalidation_1-auc:0.80382                           \n",
      "[14]\tvalidation_0-auc:0.90002\tvalidation_1-auc:0.80658                           \n",
      "[15]\tvalidation_0-auc:0.89880\tvalidation_1-auc:0.80523                           \n",
      "[16]\tvalidation_0-auc:0.90156\tvalidation_1-auc:0.80820                           \n",
      "[17]\tvalidation_0-auc:0.90122\tvalidation_1-auc:0.80721                           \n",
      "[18]\tvalidation_0-auc:0.90456\tvalidation_1-auc:0.81030                           \n",
      "[19]\tvalidation_0-auc:0.90592\tvalidation_1-auc:0.81289                           \n",
      "[20]\tvalidation_0-auc:0.90750\tvalidation_1-auc:0.81462                           \n",
      "[21]\tvalidation_0-auc:0.90719\tvalidation_1-auc:0.81291                           \n",
      "[22]\tvalidation_0-auc:0.90838\tvalidation_1-auc:0.81404                           \n",
      "[23]\tvalidation_0-auc:0.90840\tvalidation_1-auc:0.81340                           \n",
      "[24]\tvalidation_0-auc:0.90968\tvalidation_1-auc:0.81513                           \n",
      "[25]\tvalidation_0-auc:0.91035\tvalidation_1-auc:0.81616                           \n",
      "[26]\tvalidation_0-auc:0.91129\tvalidation_1-auc:0.81666                           \n",
      "[27]\tvalidation_0-auc:0.91255\tvalidation_1-auc:0.81754                           \n",
      "[28]\tvalidation_0-auc:0.91274\tvalidation_1-auc:0.81672                           \n",
      "[29]\tvalidation_0-auc:0.91272\tvalidation_1-auc:0.81600                           \n",
      "[0]\tvalidation_0-auc:0.82226\tvalidation_1-auc:0.71770                            \n",
      "[1]\tvalidation_0-auc:0.88796\tvalidation_1-auc:0.79525                            \n",
      "[2]\tvalidation_0-auc:0.88824\tvalidation_1-auc:0.78607                            \n",
      "[3]\tvalidation_0-auc:0.89843\tvalidation_1-auc:0.80279                            \n",
      "[4]\tvalidation_0-auc:0.89934\tvalidation_1-auc:0.79816                            \n",
      "[5]\tvalidation_0-auc:0.90917\tvalidation_1-auc:0.80620                            \n",
      "[6]\tvalidation_0-auc:0.91573\tvalidation_1-auc:0.80958                            \n",
      "[7]\tvalidation_0-auc:0.91821\tvalidation_1-auc:0.81476                            \n",
      "[8]\tvalidation_0-auc:0.92292\tvalidation_1-auc:0.81796                            \n",
      "[9]\tvalidation_0-auc:0.92560\tvalidation_1-auc:0.82001                            \n",
      "[10]\tvalidation_0-auc:0.92821\tvalidation_1-auc:0.82067                           \n",
      "[11]\tvalidation_0-auc:0.92998\tvalidation_1-auc:0.82087                           \n",
      "[12]\tvalidation_0-auc:0.93103\tvalidation_1-auc:0.82205                           \n",
      "[13]\tvalidation_0-auc:0.93365\tvalidation_1-auc:0.81987                           \n",
      "[14]\tvalidation_0-auc:0.93698\tvalidation_1-auc:0.82132                           \n",
      "[15]\tvalidation_0-auc:0.93966\tvalidation_1-auc:0.82204                           \n",
      "[16]\tvalidation_0-auc:0.94133\tvalidation_1-auc:0.82229                           \n",
      "[17]\tvalidation_0-auc:0.94310\tvalidation_1-auc:0.82105                           \n",
      "[18]\tvalidation_0-auc:0.94486\tvalidation_1-auc:0.82022                           \n",
      "[19]\tvalidation_0-auc:0.94651\tvalidation_1-auc:0.81957                           \n",
      "[20]\tvalidation_0-auc:0.94808\tvalidation_1-auc:0.82031                           \n",
      "[21]\tvalidation_0-auc:0.94897\tvalidation_1-auc:0.82020                           \n",
      "[22]\tvalidation_0-auc:0.94990\tvalidation_1-auc:0.82003                           \n",
      "[23]\tvalidation_0-auc:0.95102\tvalidation_1-auc:0.81948                           \n",
      "[24]\tvalidation_0-auc:0.95178\tvalidation_1-auc:0.82024                           \n",
      "[25]\tvalidation_0-auc:0.95229\tvalidation_1-auc:0.82000                           \n",
      "[26]\tvalidation_0-auc:0.95321\tvalidation_1-auc:0.82000                           \n",
      "[0]\tvalidation_0-auc:0.79374\tvalidation_1-auc:0.73408                            \n",
      "[1]\tvalidation_0-auc:0.79769\tvalidation_1-auc:0.75125                            \n",
      "[2]\tvalidation_0-auc:0.79887\tvalidation_1-auc:0.75215                            \n",
      "[3]\tvalidation_0-auc:0.84235\tvalidation_1-auc:0.79362                            \n",
      "[4]\tvalidation_0-auc:0.83830\tvalidation_1-auc:0.78971                            \n",
      "[5]\tvalidation_0-auc:0.84766\tvalidation_1-auc:0.80237                            \n",
      "[6]\tvalidation_0-auc:0.85190\tvalidation_1-auc:0.80888                            \n",
      "[7]\tvalidation_0-auc:0.85503\tvalidation_1-auc:0.81440                            \n",
      "[8]\tvalidation_0-auc:0.85499\tvalidation_1-auc:0.81115                            \n",
      "[9]\tvalidation_0-auc:0.85825\tvalidation_1-auc:0.81548                            \n",
      "[10]\tvalidation_0-auc:0.85739\tvalidation_1-auc:0.81256                           \n",
      "[11]\tvalidation_0-auc:0.85955\tvalidation_1-auc:0.81558                           \n",
      "[12]\tvalidation_0-auc:0.85812\tvalidation_1-auc:0.81291                           \n",
      "[13]\tvalidation_0-auc:0.85839\tvalidation_1-auc:0.81188                           \n",
      "[14]\tvalidation_0-auc:0.85834\tvalidation_1-auc:0.81099                           \n",
      "[15]\tvalidation_0-auc:0.85743\tvalidation_1-auc:0.80940                           \n",
      "[16]\tvalidation_0-auc:0.86048\tvalidation_1-auc:0.81201                           \n",
      "[17]\tvalidation_0-auc:0.86009\tvalidation_1-auc:0.81121                           \n",
      "[18]\tvalidation_0-auc:0.86228\tvalidation_1-auc:0.81443                           \n",
      "[19]\tvalidation_0-auc:0.86395\tvalidation_1-auc:0.81601                           \n",
      "[20]\tvalidation_0-auc:0.86565\tvalidation_1-auc:0.81790                           \n",
      "[21]\tvalidation_0-auc:0.86478\tvalidation_1-auc:0.81666                           \n",
      "[22]\tvalidation_0-auc:0.86657\tvalidation_1-auc:0.81830                           \n",
      "[23]\tvalidation_0-auc:0.86635\tvalidation_1-auc:0.81783                           \n",
      "[24]\tvalidation_0-auc:0.86789\tvalidation_1-auc:0.81916                           \n",
      "[25]\tvalidation_0-auc:0.86912\tvalidation_1-auc:0.82072                           \n",
      "[26]\tvalidation_0-auc:0.87022\tvalidation_1-auc:0.82174                           \n",
      "[27]\tvalidation_0-auc:0.87147\tvalidation_1-auc:0.82292                           \n",
      "[28]\tvalidation_0-auc:0.87145\tvalidation_1-auc:0.82266                           \n",
      "[29]\tvalidation_0-auc:0.87085\tvalidation_1-auc:0.82157                           \n",
      "[0]\tvalidation_0-auc:0.80447\tvalidation_1-auc:0.73868                            \n",
      "[1]\tvalidation_0-auc:0.86647\tvalidation_1-auc:0.80391                            \n",
      "[2]\tvalidation_0-auc:0.85988\tvalidation_1-auc:0.79334                            \n",
      "[3]\tvalidation_0-auc:0.86894\tvalidation_1-auc:0.80449                            \n",
      "[4]\tvalidation_0-auc:0.86779\tvalidation_1-auc:0.80258                            \n",
      "[5]\tvalidation_0-auc:0.87308\tvalidation_1-auc:0.80987                            \n",
      "[6]\tvalidation_0-auc:0.87651\tvalidation_1-auc:0.81312                            \n",
      "[7]\tvalidation_0-auc:0.87803\tvalidation_1-auc:0.81805                            \n",
      "[8]\tvalidation_0-auc:0.87916\tvalidation_1-auc:0.81384                            \n",
      "[9]\tvalidation_0-auc:0.88165\tvalidation_1-auc:0.81693                            \n",
      "[10]\tvalidation_0-auc:0.88320\tvalidation_1-auc:0.81833                           \n",
      "[11]\tvalidation_0-auc:0.88441\tvalidation_1-auc:0.81921                           \n",
      "[12]\tvalidation_0-auc:0.88525\tvalidation_1-auc:0.82068                           \n",
      "[13]\tvalidation_0-auc:0.88626\tvalidation_1-auc:0.81909                           \n",
      "[14]\tvalidation_0-auc:0.88866\tvalidation_1-auc:0.82093                           \n",
      "[15]\tvalidation_0-auc:0.89117\tvalidation_1-auc:0.82247                           \n",
      "[16]\tvalidation_0-auc:0.89295\tvalidation_1-auc:0.82316                           \n",
      "[17]\tvalidation_0-auc:0.89451\tvalidation_1-auc:0.82445                           \n",
      "[18]\tvalidation_0-auc:0.89605\tvalidation_1-auc:0.82601                           \n",
      "[19]\tvalidation_0-auc:0.89677\tvalidation_1-auc:0.82707                           \n",
      "[20]\tvalidation_0-auc:0.89771\tvalidation_1-auc:0.82745                           \n",
      "[21]\tvalidation_0-auc:0.89867\tvalidation_1-auc:0.82813                           \n",
      "[22]\tvalidation_0-auc:0.89983\tvalidation_1-auc:0.82893                           \n",
      "[23]\tvalidation_0-auc:0.90081\tvalidation_1-auc:0.82897                           \n",
      "[24]\tvalidation_0-auc:0.90158\tvalidation_1-auc:0.82940                           \n",
      "[25]\tvalidation_0-auc:0.90263\tvalidation_1-auc:0.82962                           \n",
      "[26]\tvalidation_0-auc:0.90333\tvalidation_1-auc:0.82946                           \n",
      "[27]\tvalidation_0-auc:0.90389\tvalidation_1-auc:0.82945                           \n",
      "[28]\tvalidation_0-auc:0.90414\tvalidation_1-auc:0.82941                           \n",
      "[29]\tvalidation_0-auc:0.90490\tvalidation_1-auc:0.82963                           \n",
      "[0]\tvalidation_0-auc:0.77079\tvalidation_1-auc:0.73421                            \n",
      "[1]\tvalidation_0-auc:0.78014\tvalidation_1-auc:0.74194                            \n",
      "[2]\tvalidation_0-auc:0.78206\tvalidation_1-auc:0.74561                            \n",
      "[3]\tvalidation_0-auc:0.82481\tvalidation_1-auc:0.79424                            \n",
      "[4]\tvalidation_0-auc:0.82250\tvalidation_1-auc:0.79159                            \n",
      "[5]\tvalidation_0-auc:0.83555\tvalidation_1-auc:0.80444                            \n",
      "[6]\tvalidation_0-auc:0.84091\tvalidation_1-auc:0.80989                            \n",
      "[7]\tvalidation_0-auc:0.84527\tvalidation_1-auc:0.81556                            \n",
      "[8]\tvalidation_0-auc:0.84390\tvalidation_1-auc:0.81172                            \n",
      "[9]\tvalidation_0-auc:0.84751\tvalidation_1-auc:0.81706                            \n",
      "[10]\tvalidation_0-auc:0.84650\tvalidation_1-auc:0.81369                           \n",
      "[11]\tvalidation_0-auc:0.84954\tvalidation_1-auc:0.81797                           \n",
      "[12]\tvalidation_0-auc:0.84840\tvalidation_1-auc:0.81698                           \n",
      "[13]\tvalidation_0-auc:0.84832\tvalidation_1-auc:0.81508                           \n",
      "[14]\tvalidation_0-auc:0.85112\tvalidation_1-auc:0.81853                           \n",
      "[15]\tvalidation_0-auc:0.85001\tvalidation_1-auc:0.81688                           \n",
      "[16]\tvalidation_0-auc:0.85249\tvalidation_1-auc:0.81984                           \n",
      "[17]\tvalidation_0-auc:0.85280\tvalidation_1-auc:0.81839                           \n",
      "[18]\tvalidation_0-auc:0.85504\tvalidation_1-auc:0.82206                           \n",
      "[19]\tvalidation_0-auc:0.85771\tvalidation_1-auc:0.82472                           \n",
      "[20]\tvalidation_0-auc:0.85999\tvalidation_1-auc:0.82661                           \n",
      "[21]\tvalidation_0-auc:0.85906\tvalidation_1-auc:0.82537                           \n",
      "[22]\tvalidation_0-auc:0.86058\tvalidation_1-auc:0.82627                           \n",
      "[23]\tvalidation_0-auc:0.86047\tvalidation_1-auc:0.82643                           \n",
      "[24]\tvalidation_0-auc:0.86212\tvalidation_1-auc:0.82760                           \n",
      "[25]\tvalidation_0-auc:0.86363\tvalidation_1-auc:0.82859                           \n",
      "[26]\tvalidation_0-auc:0.86521\tvalidation_1-auc:0.82995                           \n",
      "[27]\tvalidation_0-auc:0.86629\tvalidation_1-auc:0.83023                           \n",
      "[28]\tvalidation_0-auc:0.86631\tvalidation_1-auc:0.82967                           \n",
      "[29]\tvalidation_0-auc:0.86601\tvalidation_1-auc:0.82928                           \n",
      "[0]\tvalidation_0-auc:0.82372\tvalidation_1-auc:0.71892                            \n",
      "[1]\tvalidation_0-auc:0.83497\tvalidation_1-auc:0.73888                            \n",
      "[2]\tvalidation_0-auc:0.83841\tvalidation_1-auc:0.74703                            \n",
      "[3]\tvalidation_0-auc:0.88096\tvalidation_1-auc:0.78684                            \n",
      "[4]\tvalidation_0-auc:0.87876\tvalidation_1-auc:0.78465                            \n",
      "[5]\tvalidation_0-auc:0.88880\tvalidation_1-auc:0.79924                            \n",
      "[6]\tvalidation_0-auc:0.89419\tvalidation_1-auc:0.80893                            \n",
      "[7]\tvalidation_0-auc:0.89468\tvalidation_1-auc:0.80641                            \n",
      "[8]\tvalidation_0-auc:0.89610\tvalidation_1-auc:0.80357                            \n",
      "[9]\tvalidation_0-auc:0.90467\tvalidation_1-auc:0.80769                            \n",
      "[10]\tvalidation_0-auc:0.90517\tvalidation_1-auc:0.80422                           \n",
      "[11]\tvalidation_0-auc:0.91053\tvalidation_1-auc:0.81153                           \n",
      "[12]\tvalidation_0-auc:0.91057\tvalidation_1-auc:0.81028                           \n",
      "[13]\tvalidation_0-auc:0.91304\tvalidation_1-auc:0.81036                           \n",
      "[14]\tvalidation_0-auc:0.91490\tvalidation_1-auc:0.80906                           \n",
      "[15]\tvalidation_0-auc:0.91521\tvalidation_1-auc:0.80733                           \n",
      "[16]\tvalidation_0-auc:0.91709\tvalidation_1-auc:0.80550                           \n",
      "[17]\tvalidation_0-auc:0.91777\tvalidation_1-auc:0.80500                           \n",
      "[18]\tvalidation_0-auc:0.92260\tvalidation_1-auc:0.81043                           \n",
      "[19]\tvalidation_0-auc:0.92599\tvalidation_1-auc:0.81469                           \n",
      "[20]\tvalidation_0-auc:0.92875\tvalidation_1-auc:0.81741                           \n",
      "[21]\tvalidation_0-auc:0.92916\tvalidation_1-auc:0.81554                           \n",
      "[22]\tvalidation_0-auc:0.93091\tvalidation_1-auc:0.81499                           \n",
      "[23]\tvalidation_0-auc:0.93153\tvalidation_1-auc:0.81420                           \n",
      "[24]\tvalidation_0-auc:0.93454\tvalidation_1-auc:0.81613                           \n",
      "[25]\tvalidation_0-auc:0.93614\tvalidation_1-auc:0.81849                           \n",
      "[26]\tvalidation_0-auc:0.93689\tvalidation_1-auc:0.81753                           \n",
      "[27]\tvalidation_0-auc:0.93839\tvalidation_1-auc:0.81942                           \n",
      "[28]\tvalidation_0-auc:0.93994\tvalidation_1-auc:0.81914                           \n",
      "[29]\tvalidation_0-auc:0.94012\tvalidation_1-auc:0.81894                           \n",
      "[0]\tvalidation_0-auc:0.78690\tvalidation_1-auc:0.73795                            \n",
      "[1]\tvalidation_0-auc:0.79534\tvalidation_1-auc:0.74367                            \n",
      "[2]\tvalidation_0-auc:0.79484\tvalidation_1-auc:0.74946                            \n",
      "[3]\tvalidation_0-auc:0.83647\tvalidation_1-auc:0.79326                            \n",
      "[4]\tvalidation_0-auc:0.83449\tvalidation_1-auc:0.79329                            \n",
      "[5]\tvalidation_0-auc:0.84629\tvalidation_1-auc:0.80603                            \n",
      "[6]\tvalidation_0-auc:0.85222\tvalidation_1-auc:0.81229                            \n",
      "[7]\tvalidation_0-auc:0.85567\tvalidation_1-auc:0.81682                            \n",
      "[8]\tvalidation_0-auc:0.85548\tvalidation_1-auc:0.81399                            \n",
      "[9]\tvalidation_0-auc:0.85861\tvalidation_1-auc:0.81856                            \n",
      "[10]\tvalidation_0-auc:0.85771\tvalidation_1-auc:0.81518                           \n",
      "[11]\tvalidation_0-auc:0.86125\tvalidation_1-auc:0.81979                           \n",
      "[12]\tvalidation_0-auc:0.86335\tvalidation_1-auc:0.82244                           \n",
      "[13]\tvalidation_0-auc:0.86278\tvalidation_1-auc:0.82005                           \n",
      "[14]\tvalidation_0-auc:0.86565\tvalidation_1-auc:0.82215                           \n",
      "[15]\tvalidation_0-auc:0.86791\tvalidation_1-auc:0.82489                           \n",
      "[16]\tvalidation_0-auc:0.86996\tvalidation_1-auc:0.82648                           \n",
      "[17]\tvalidation_0-auc:0.87116\tvalidation_1-auc:0.82760                           \n",
      "[18]\tvalidation_0-auc:0.87288\tvalidation_1-auc:0.82890                           \n",
      "[19]\tvalidation_0-auc:0.87381\tvalidation_1-auc:0.82934                           \n",
      "[20]\tvalidation_0-auc:0.87542\tvalidation_1-auc:0.82980                           \n",
      "[21]\tvalidation_0-auc:0.87526\tvalidation_1-auc:0.82930                           \n",
      "[22]\tvalidation_0-auc:0.87687\tvalidation_1-auc:0.82984                           \n",
      "[23]\tvalidation_0-auc:0.87799\tvalidation_1-auc:0.83037                           \n",
      "[24]\tvalidation_0-auc:0.87880\tvalidation_1-auc:0.83079                           \n",
      "[25]\tvalidation_0-auc:0.87973\tvalidation_1-auc:0.83050                           \n",
      "[26]\tvalidation_0-auc:0.88042\tvalidation_1-auc:0.83047                           \n",
      "[27]\tvalidation_0-auc:0.88144\tvalidation_1-auc:0.83081                           \n",
      "[28]\tvalidation_0-auc:0.88154\tvalidation_1-auc:0.83089                           \n",
      "[29]\tvalidation_0-auc:0.88234\tvalidation_1-auc:0.83085                           \n",
      "[0]\tvalidation_0-auc:0.81400\tvalidation_1-auc:0.72028                            \n",
      "[1]\tvalidation_0-auc:0.82238\tvalidation_1-auc:0.72925                            \n",
      "[2]\tvalidation_0-auc:0.82775\tvalidation_1-auc:0.73742                            \n",
      "[3]\tvalidation_0-auc:0.87883\tvalidation_1-auc:0.78179                            \n",
      "[4]\tvalidation_0-auc:0.88164\tvalidation_1-auc:0.77922                            \n",
      "[5]\tvalidation_0-auc:0.89120\tvalidation_1-auc:0.79690                            \n",
      "[6]\tvalidation_0-auc:0.90027\tvalidation_1-auc:0.80494                            \n",
      "[7]\tvalidation_0-auc:0.90428\tvalidation_1-auc:0.80819                            \n",
      "[8]\tvalidation_0-auc:0.90560\tvalidation_1-auc:0.80687                            \n",
      "[9]\tvalidation_0-auc:0.91115\tvalidation_1-auc:0.81003                            \n",
      "[10]\tvalidation_0-auc:0.91489\tvalidation_1-auc:0.81330                           \n",
      "[11]\tvalidation_0-auc:0.91743\tvalidation_1-auc:0.81527                           \n",
      "[12]\tvalidation_0-auc:0.91995\tvalidation_1-auc:0.81797                           \n",
      "[13]\tvalidation_0-auc:0.92264\tvalidation_1-auc:0.81614                           \n",
      "[14]\tvalidation_0-auc:0.92567\tvalidation_1-auc:0.81871                           \n",
      "[15]\tvalidation_0-auc:0.92771\tvalidation_1-auc:0.82039                           \n",
      "[16]\tvalidation_0-auc:0.93073\tvalidation_1-auc:0.82253                           \n",
      "[17]\tvalidation_0-auc:0.93439\tvalidation_1-auc:0.82314                           \n",
      "[18]\tvalidation_0-auc:0.93643\tvalidation_1-auc:0.82334                           \n",
      "[19]\tvalidation_0-auc:0.93825\tvalidation_1-auc:0.82394                           \n",
      "[20]\tvalidation_0-auc:0.94045\tvalidation_1-auc:0.82333                           \n",
      "[21]\tvalidation_0-auc:0.94162\tvalidation_1-auc:0.82214                           \n",
      "[22]\tvalidation_0-auc:0.94358\tvalidation_1-auc:0.82306                           \n",
      "[23]\tvalidation_0-auc:0.94503\tvalidation_1-auc:0.82367                           \n",
      "[24]\tvalidation_0-auc:0.94648\tvalidation_1-auc:0.82367                           \n",
      "[25]\tvalidation_0-auc:0.94780\tvalidation_1-auc:0.82406                           \n",
      "[26]\tvalidation_0-auc:0.94915\tvalidation_1-auc:0.82483                           \n",
      "[27]\tvalidation_0-auc:0.95006\tvalidation_1-auc:0.82427                           \n",
      "[28]\tvalidation_0-auc:0.95066\tvalidation_1-auc:0.82369                           \n",
      "[29]\tvalidation_0-auc:0.95145\tvalidation_1-auc:0.82400                           \n",
      "[0]\tvalidation_0-auc:0.80401\tvalidation_1-auc:0.74229                            \n",
      "[1]\tvalidation_0-auc:0.86710\tvalidation_1-auc:0.80582                            \n",
      "[2]\tvalidation_0-auc:0.86033\tvalidation_1-auc:0.79246                            \n",
      "[3]\tvalidation_0-auc:0.87020\tvalidation_1-auc:0.80558                            \n",
      "[4]\tvalidation_0-auc:0.86874\tvalidation_1-auc:0.80189                            \n",
      "[5]\tvalidation_0-auc:0.87458\tvalidation_1-auc:0.80822                            \n",
      "[6]\tvalidation_0-auc:0.87859\tvalidation_1-auc:0.81106                            \n",
      "[7]\tvalidation_0-auc:0.88107\tvalidation_1-auc:0.81716                            \n",
      "[8]\tvalidation_0-auc:0.88344\tvalidation_1-auc:0.81930                            \n",
      "[9]\tvalidation_0-auc:0.88507\tvalidation_1-auc:0.82054                            \n",
      "[10]\tvalidation_0-auc:0.88883\tvalidation_1-auc:0.82282                           \n",
      "[11]\tvalidation_0-auc:0.89171\tvalidation_1-auc:0.82504                           \n",
      "[12]\tvalidation_0-auc:0.89292\tvalidation_1-auc:0.82667                           \n",
      "[13]\tvalidation_0-auc:0.89429\tvalidation_1-auc:0.82368                           \n",
      "[14]\tvalidation_0-auc:0.89587\tvalidation_1-auc:0.82541                           \n",
      "[15]\tvalidation_0-auc:0.89673\tvalidation_1-auc:0.82701                           \n",
      "[16]\tvalidation_0-auc:0.89849\tvalidation_1-auc:0.82789                           \n",
      "[17]\tvalidation_0-auc:0.89992\tvalidation_1-auc:0.82859                           \n",
      "[18]\tvalidation_0-auc:0.90086\tvalidation_1-auc:0.82864                           \n",
      "[19]\tvalidation_0-auc:0.90184\tvalidation_1-auc:0.82835                           \n",
      "[20]\tvalidation_0-auc:0.90299\tvalidation_1-auc:0.82842                           \n",
      "[21]\tvalidation_0-auc:0.90379\tvalidation_1-auc:0.82808                           \n",
      "[22]\tvalidation_0-auc:0.90458\tvalidation_1-auc:0.82829                           \n",
      "[23]\tvalidation_0-auc:0.90560\tvalidation_1-auc:0.82778                           \n",
      "[24]\tvalidation_0-auc:0.90712\tvalidation_1-auc:0.82734                           \n",
      "[25]\tvalidation_0-auc:0.90882\tvalidation_1-auc:0.82679                           \n",
      "[26]\tvalidation_0-auc:0.91013\tvalidation_1-auc:0.82671                           \n",
      "[27]\tvalidation_0-auc:0.91092\tvalidation_1-auc:0.82601                           \n",
      "[0]\tvalidation_0-auc:0.78423\tvalidation_1-auc:0.73707                            \n",
      "[1]\tvalidation_0-auc:0.79504\tvalidation_1-auc:0.74770                            \n",
      "[2]\tvalidation_0-auc:0.79683\tvalidation_1-auc:0.75154                            \n",
      "[3]\tvalidation_0-auc:0.83821\tvalidation_1-auc:0.79703                            \n",
      "[4]\tvalidation_0-auc:0.83644\tvalidation_1-auc:0.79693                            \n",
      "[5]\tvalidation_0-auc:0.84689\tvalidation_1-auc:0.80819                            \n",
      "[6]\tvalidation_0-auc:0.85220\tvalidation_1-auc:0.81223                            \n",
      "[7]\tvalidation_0-auc:0.85586\tvalidation_1-auc:0.81853                            \n",
      "[8]\tvalidation_0-auc:0.85494\tvalidation_1-auc:0.81591                            \n",
      "[9]\tvalidation_0-auc:0.85944\tvalidation_1-auc:0.81988                            \n",
      "[10]\tvalidation_0-auc:0.85868\tvalidation_1-auc:0.81629                           \n",
      "[11]\tvalidation_0-auc:0.86175\tvalidation_1-auc:0.82123                           \n",
      "[12]\tvalidation_0-auc:0.86041\tvalidation_1-auc:0.81932                           \n",
      "[13]\tvalidation_0-auc:0.85998\tvalidation_1-auc:0.81755                           \n",
      "[14]\tvalidation_0-auc:0.86322\tvalidation_1-auc:0.82074                           \n",
      "[15]\tvalidation_0-auc:0.86329\tvalidation_1-auc:0.81804                           \n",
      "[16]\tvalidation_0-auc:0.86631\tvalidation_1-auc:0.82169                           \n",
      "[17]\tvalidation_0-auc:0.86590\tvalidation_1-auc:0.82010                           \n",
      "[18]\tvalidation_0-auc:0.86815\tvalidation_1-auc:0.82331                           \n",
      "[19]\tvalidation_0-auc:0.87013\tvalidation_1-auc:0.82590                           \n",
      "[20]\tvalidation_0-auc:0.87211\tvalidation_1-auc:0.82795                           \n",
      "[21]\tvalidation_0-auc:0.87181\tvalidation_1-auc:0.82690                           \n",
      "[22]\tvalidation_0-auc:0.87386\tvalidation_1-auc:0.82840                           \n",
      "[23]\tvalidation_0-auc:0.87422\tvalidation_1-auc:0.82796                           \n",
      "[24]\tvalidation_0-auc:0.87587\tvalidation_1-auc:0.82981                           \n",
      "[25]\tvalidation_0-auc:0.87705\tvalidation_1-auc:0.83053                           \n",
      "[26]\tvalidation_0-auc:0.87843\tvalidation_1-auc:0.83142                           \n",
      "[27]\tvalidation_0-auc:0.87983\tvalidation_1-auc:0.83204                           \n",
      "[28]\tvalidation_0-auc:0.88005\tvalidation_1-auc:0.83176                           \n",
      "[29]\tvalidation_0-auc:0.88005\tvalidation_1-auc:0.83156                           \n",
      "[0]\tvalidation_0-auc:0.75719\tvalidation_1-auc:0.72674                            \n",
      "[1]\tvalidation_0-auc:0.76275\tvalidation_1-auc:0.73207                            \n",
      "[2]\tvalidation_0-auc:0.77742\tvalidation_1-auc:0.75222                            \n",
      "[3]\tvalidation_0-auc:0.82408\tvalidation_1-auc:0.79543                            \n",
      "[4]\tvalidation_0-auc:0.82319\tvalidation_1-auc:0.79317                            \n",
      "[5]\tvalidation_0-auc:0.83408\tvalidation_1-auc:0.80355                            \n",
      "[6]\tvalidation_0-auc:0.84161\tvalidation_1-auc:0.81235                            \n",
      "[7]\tvalidation_0-auc:0.84828\tvalidation_1-auc:0.81872                            \n",
      "[8]\tvalidation_0-auc:0.84856\tvalidation_1-auc:0.81676                            \n",
      "[9]\tvalidation_0-auc:0.85352\tvalidation_1-auc:0.82265                            \n",
      "[10]\tvalidation_0-auc:0.85483\tvalidation_1-auc:0.82246                           \n",
      "[11]\tvalidation_0-auc:0.85967\tvalidation_1-auc:0.82730                           \n",
      "[12]\tvalidation_0-auc:0.86159\tvalidation_1-auc:0.82561                           \n",
      "[13]\tvalidation_0-auc:0.86282\tvalidation_1-auc:0.82437                           \n",
      "[14]\tvalidation_0-auc:0.86589\tvalidation_1-auc:0.82831                           \n",
      "[15]\tvalidation_0-auc:0.86888\tvalidation_1-auc:0.83062                           \n",
      "[16]\tvalidation_0-auc:0.87028\tvalidation_1-auc:0.83244                           \n",
      "[17]\tvalidation_0-auc:0.87147\tvalidation_1-auc:0.83148                           \n",
      "[18]\tvalidation_0-auc:0.87346\tvalidation_1-auc:0.83166                           \n",
      "[19]\tvalidation_0-auc:0.87481\tvalidation_1-auc:0.83216                           \n",
      "[20]\tvalidation_0-auc:0.87575\tvalidation_1-auc:0.83265                           \n",
      "[21]\tvalidation_0-auc:0.87739\tvalidation_1-auc:0.83248                           \n",
      "[22]\tvalidation_0-auc:0.87853\tvalidation_1-auc:0.83256                           \n",
      "[23]\tvalidation_0-auc:0.87928\tvalidation_1-auc:0.83321                           \n",
      "[24]\tvalidation_0-auc:0.88002\tvalidation_1-auc:0.83343                           \n",
      "[25]\tvalidation_0-auc:0.88035\tvalidation_1-auc:0.83353                           \n",
      "[26]\tvalidation_0-auc:0.88139\tvalidation_1-auc:0.83327                           \n",
      "[27]\tvalidation_0-auc:0.88189\tvalidation_1-auc:0.83345                           \n",
      "[28]\tvalidation_0-auc:0.88217\tvalidation_1-auc:0.83323                           \n",
      "[29]\tvalidation_0-auc:0.88352\tvalidation_1-auc:0.83370                           \n",
      "[0]\tvalidation_0-auc:0.75719\tvalidation_1-auc:0.72674                             \n",
      "[1]\tvalidation_0-auc:0.76275\tvalidation_1-auc:0.73207                             \n",
      "[2]\tvalidation_0-auc:0.77743\tvalidation_1-auc:0.75222                             \n",
      "[3]\tvalidation_0-auc:0.82371\tvalidation_1-auc:0.79587                             \n",
      "[4]\tvalidation_0-auc:0.82240\tvalidation_1-auc:0.79270                             \n",
      "[5]\tvalidation_0-auc:0.83410\tvalidation_1-auc:0.80425                             \n",
      "[6]\tvalidation_0-auc:0.84299\tvalidation_1-auc:0.81136                             \n",
      "[7]\tvalidation_0-auc:0.84885\tvalidation_1-auc:0.81722                             \n",
      "[8]\tvalidation_0-auc:0.84956\tvalidation_1-auc:0.81543                             \n",
      "[9]\tvalidation_0-auc:0.85400\tvalidation_1-auc:0.82183                             \n",
      "[10]\tvalidation_0-auc:0.85600\tvalidation_1-auc:0.82087                            \n",
      "[11]\tvalidation_0-auc:0.86068\tvalidation_1-auc:0.82582                            \n",
      "[12]\tvalidation_0-auc:0.86161\tvalidation_1-auc:0.82307                            \n",
      "[13]\tvalidation_0-auc:0.86299\tvalidation_1-auc:0.82181                            \n",
      "[14]\tvalidation_0-auc:0.86597\tvalidation_1-auc:0.82541                            \n",
      "[15]\tvalidation_0-auc:0.86880\tvalidation_1-auc:0.82764                            \n",
      "[16]\tvalidation_0-auc:0.87031\tvalidation_1-auc:0.82945                            \n",
      "[17]\tvalidation_0-auc:0.87157\tvalidation_1-auc:0.82852                            \n",
      "[18]\tvalidation_0-auc:0.87284\tvalidation_1-auc:0.82935                            \n",
      "[19]\tvalidation_0-auc:0.87465\tvalidation_1-auc:0.83055                            \n",
      "[20]\tvalidation_0-auc:0.87562\tvalidation_1-auc:0.83112                            \n",
      "[21]\tvalidation_0-auc:0.87663\tvalidation_1-auc:0.83125                            \n",
      "[22]\tvalidation_0-auc:0.87738\tvalidation_1-auc:0.83179                            \n",
      "[23]\tvalidation_0-auc:0.87843\tvalidation_1-auc:0.83181                            \n",
      "[24]\tvalidation_0-auc:0.87958\tvalidation_1-auc:0.83222                            \n",
      "[25]\tvalidation_0-auc:0.88019\tvalidation_1-auc:0.83266                            \n",
      "[26]\tvalidation_0-auc:0.88113\tvalidation_1-auc:0.83242                            \n",
      "[27]\tvalidation_0-auc:0.88169\tvalidation_1-auc:0.83274                            \n",
      "[28]\tvalidation_0-auc:0.88194\tvalidation_1-auc:0.83272                            \n",
      "[29]\tvalidation_0-auc:0.88325\tvalidation_1-auc:0.83229                            \n",
      "[0]\tvalidation_0-auc:0.78540\tvalidation_1-auc:0.73425                             \n",
      "[1]\tvalidation_0-auc:0.79369\tvalidation_1-auc:0.74149                             \n",
      "[2]\tvalidation_0-auc:0.80442\tvalidation_1-auc:0.74919                             \n",
      "[3]\tvalidation_0-auc:0.85253\tvalidation_1-auc:0.79325                             \n",
      "[4]\tvalidation_0-auc:0.85539\tvalidation_1-auc:0.78831                             \n",
      "[5]\tvalidation_0-auc:0.86805\tvalidation_1-auc:0.80278                             \n",
      "[6]\tvalidation_0-auc:0.87498\tvalidation_1-auc:0.81287                             \n",
      "[7]\tvalidation_0-auc:0.88036\tvalidation_1-auc:0.81845                             \n",
      "[8]\tvalidation_0-auc:0.88313\tvalidation_1-auc:0.81442                             \n",
      "[9]\tvalidation_0-auc:0.89113\tvalidation_1-auc:0.81893                             \n",
      "[10]\tvalidation_0-auc:0.89256\tvalidation_1-auc:0.81688                            \n",
      "[11]\tvalidation_0-auc:0.89794\tvalidation_1-auc:0.82192                            \n",
      "[12]\tvalidation_0-auc:0.89949\tvalidation_1-auc:0.82054                            \n",
      "[13]\tvalidation_0-auc:0.90067\tvalidation_1-auc:0.81880                            \n",
      "[14]\tvalidation_0-auc:0.90641\tvalidation_1-auc:0.82103                            \n",
      "[15]\tvalidation_0-auc:0.90769\tvalidation_1-auc:0.81999                            \n",
      "[16]\tvalidation_0-auc:0.91055\tvalidation_1-auc:0.82478                            \n",
      "[17]\tvalidation_0-auc:0.91233\tvalidation_1-auc:0.82354                            \n",
      "[18]\tvalidation_0-auc:0.91438\tvalidation_1-auc:0.82606                            \n",
      "[19]\tvalidation_0-auc:0.91593\tvalidation_1-auc:0.82682                            \n",
      "[20]\tvalidation_0-auc:0.91815\tvalidation_1-auc:0.82691                            \n",
      "[21]\tvalidation_0-auc:0.91920\tvalidation_1-auc:0.82629                            \n",
      "[22]\tvalidation_0-auc:0.92045\tvalidation_1-auc:0.82756                            \n",
      "[23]\tvalidation_0-auc:0.92142\tvalidation_1-auc:0.82775                            \n",
      "[24]\tvalidation_0-auc:0.92214\tvalidation_1-auc:0.82863                            \n",
      "[25]\tvalidation_0-auc:0.92271\tvalidation_1-auc:0.82869                            \n",
      "[26]\tvalidation_0-auc:0.92330\tvalidation_1-auc:0.82905                            \n",
      "[27]\tvalidation_0-auc:0.92408\tvalidation_1-auc:0.82892                            \n",
      "[28]\tvalidation_0-auc:0.92424\tvalidation_1-auc:0.82868                            \n",
      "[29]\tvalidation_0-auc:0.92446\tvalidation_1-auc:0.82839                            \n",
      "[0]\tvalidation_0-auc:0.75725\tvalidation_1-auc:0.72674                             \n",
      "[1]\tvalidation_0-auc:0.76278\tvalidation_1-auc:0.73212                             \n",
      "[2]\tvalidation_0-auc:0.77720\tvalidation_1-auc:0.75220                             \n",
      "[3]\tvalidation_0-auc:0.82175\tvalidation_1-auc:0.79334                             \n",
      "[4]\tvalidation_0-auc:0.82100\tvalidation_1-auc:0.79146                             \n",
      "[5]\tvalidation_0-auc:0.83233\tvalidation_1-auc:0.80233                             \n",
      "[6]\tvalidation_0-auc:0.84016\tvalidation_1-auc:0.80972                             \n",
      "[7]\tvalidation_0-auc:0.84534\tvalidation_1-auc:0.81701                             \n",
      "[8]\tvalidation_0-auc:0.84468\tvalidation_1-auc:0.81478                             \n",
      "[9]\tvalidation_0-auc:0.85031\tvalidation_1-auc:0.82031                             \n",
      "[10]\tvalidation_0-auc:0.85005\tvalidation_1-auc:0.81801                            \n",
      "[11]\tvalidation_0-auc:0.85469\tvalidation_1-auc:0.82280                            \n",
      "[12]\tvalidation_0-auc:0.85737\tvalidation_1-auc:0.82535                            \n",
      "[13]\tvalidation_0-auc:0.85724\tvalidation_1-auc:0.82504                            \n",
      "[14]\tvalidation_0-auc:0.86035\tvalidation_1-auc:0.82841                            \n",
      "[15]\tvalidation_0-auc:0.86315\tvalidation_1-auc:0.83082                            \n",
      "[16]\tvalidation_0-auc:0.86495\tvalidation_1-auc:0.83166                            \n",
      "[17]\tvalidation_0-auc:0.86617\tvalidation_1-auc:0.83176                            \n",
      "[18]\tvalidation_0-auc:0.86791\tvalidation_1-auc:0.83264                            \n",
      "[19]\tvalidation_0-auc:0.86934\tvalidation_1-auc:0.83233                            \n",
      "[20]\tvalidation_0-auc:0.87052\tvalidation_1-auc:0.83242                            \n",
      "[21]\tvalidation_0-auc:0.87216\tvalidation_1-auc:0.83202                            \n",
      "[22]\tvalidation_0-auc:0.87296\tvalidation_1-auc:0.83232                            \n",
      "[23]\tvalidation_0-auc:0.87396\tvalidation_1-auc:0.83271                            \n",
      "[24]\tvalidation_0-auc:0.87485\tvalidation_1-auc:0.83315                            \n",
      "[25]\tvalidation_0-auc:0.87533\tvalidation_1-auc:0.83322                            \n",
      "[26]\tvalidation_0-auc:0.87600\tvalidation_1-auc:0.83350                            \n",
      "[27]\tvalidation_0-auc:0.87680\tvalidation_1-auc:0.83364                            \n",
      "[28]\tvalidation_0-auc:0.87716\tvalidation_1-auc:0.83354                            \n",
      "[29]\tvalidation_0-auc:0.87786\tvalidation_1-auc:0.83334                            \n",
      "[0]\tvalidation_0-auc:0.76044\tvalidation_1-auc:0.72967                             \n",
      "[1]\tvalidation_0-auc:0.76397\tvalidation_1-auc:0.73418                             \n",
      "[2]\tvalidation_0-auc:0.77905\tvalidation_1-auc:0.75567                             \n",
      "[3]\tvalidation_0-auc:0.82360\tvalidation_1-auc:0.79627                             \n",
      "[4]\tvalidation_0-auc:0.82085\tvalidation_1-auc:0.79247                             \n",
      "[5]\tvalidation_0-auc:0.83178\tvalidation_1-auc:0.80288                             \n",
      "[6]\tvalidation_0-auc:0.83946\tvalidation_1-auc:0.81166                             \n",
      "[7]\tvalidation_0-auc:0.84453\tvalidation_1-auc:0.81792                             \n",
      "[8]\tvalidation_0-auc:0.84415\tvalidation_1-auc:0.81604                             \n",
      "[9]\tvalidation_0-auc:0.84987\tvalidation_1-auc:0.82034                             \n",
      "[10]\tvalidation_0-auc:0.84953\tvalidation_1-auc:0.81909                            \n",
      "[11]\tvalidation_0-auc:0.85301\tvalidation_1-auc:0.82332                            \n",
      "[12]\tvalidation_0-auc:0.85656\tvalidation_1-auc:0.82850                            \n",
      "[13]\tvalidation_0-auc:0.85684\tvalidation_1-auc:0.82724                            \n",
      "[14]\tvalidation_0-auc:0.85981\tvalidation_1-auc:0.82995                            \n",
      "[15]\tvalidation_0-auc:0.86187\tvalidation_1-auc:0.83230                            \n",
      "[16]\tvalidation_0-auc:0.86277\tvalidation_1-auc:0.83325                            \n",
      "[17]\tvalidation_0-auc:0.86395\tvalidation_1-auc:0.83337                            \n",
      "[18]\tvalidation_0-auc:0.86464\tvalidation_1-auc:0.83401                            \n",
      "[19]\tvalidation_0-auc:0.86561\tvalidation_1-auc:0.83399                            \n",
      "[20]\tvalidation_0-auc:0.86677\tvalidation_1-auc:0.83436                            \n",
      "[21]\tvalidation_0-auc:0.86791\tvalidation_1-auc:0.83501                            \n",
      "[22]\tvalidation_0-auc:0.86812\tvalidation_1-auc:0.83504                            \n",
      "[23]\tvalidation_0-auc:0.86913\tvalidation_1-auc:0.83530                            \n",
      "[24]\tvalidation_0-auc:0.86950\tvalidation_1-auc:0.83536                            \n",
      "[25]\tvalidation_0-auc:0.87020\tvalidation_1-auc:0.83513                            \n",
      "[26]\tvalidation_0-auc:0.87047\tvalidation_1-auc:0.83531                            \n",
      "[27]\tvalidation_0-auc:0.87108\tvalidation_1-auc:0.83573                            \n",
      "[28]\tvalidation_0-auc:0.87170\tvalidation_1-auc:0.83567                            \n",
      "[29]\tvalidation_0-auc:0.87233\tvalidation_1-auc:0.83606                            \n",
      "[0]\tvalidation_0-auc:0.79602\tvalidation_1-auc:0.72675                             \n",
      "[1]\tvalidation_0-auc:0.80689\tvalidation_1-auc:0.74512                             \n",
      "[2]\tvalidation_0-auc:0.81393\tvalidation_1-auc:0.75736                             \n",
      "[3]\tvalidation_0-auc:0.85297\tvalidation_1-auc:0.79951                             \n",
      "[4]\tvalidation_0-auc:0.85056\tvalidation_1-auc:0.79705                             \n",
      "[5]\tvalidation_0-auc:0.85908\tvalidation_1-auc:0.81046                             \n",
      "[6]\tvalidation_0-auc:0.86801\tvalidation_1-auc:0.81552                             \n",
      "[7]\tvalidation_0-auc:0.87166\tvalidation_1-auc:0.81986                             \n",
      "[8]\tvalidation_0-auc:0.87200\tvalidation_1-auc:0.81621                             \n",
      "[9]\tvalidation_0-auc:0.87806\tvalidation_1-auc:0.82121                             \n",
      "[10]\tvalidation_0-auc:0.88236\tvalidation_1-auc:0.82467                            \n",
      "[11]\tvalidation_0-auc:0.88577\tvalidation_1-auc:0.82645                            \n",
      "[12]\tvalidation_0-auc:0.88808\tvalidation_1-auc:0.82836                            \n",
      "[13]\tvalidation_0-auc:0.88871\tvalidation_1-auc:0.82867                            \n",
      "[14]\tvalidation_0-auc:0.89045\tvalidation_1-auc:0.83079                            \n",
      "[15]\tvalidation_0-auc:0.89167\tvalidation_1-auc:0.83217                            \n",
      "[16]\tvalidation_0-auc:0.89278\tvalidation_1-auc:0.83306                            \n",
      "[17]\tvalidation_0-auc:0.89398\tvalidation_1-auc:0.83260                            \n",
      "[18]\tvalidation_0-auc:0.89511\tvalidation_1-auc:0.83231                            \n",
      "[19]\tvalidation_0-auc:0.89625\tvalidation_1-auc:0.83181                            \n",
      "[20]\tvalidation_0-auc:0.89636\tvalidation_1-auc:0.83150                            \n",
      "[21]\tvalidation_0-auc:0.89689\tvalidation_1-auc:0.83135                            \n",
      "[22]\tvalidation_0-auc:0.89764\tvalidation_1-auc:0.83160                            \n",
      "[23]\tvalidation_0-auc:0.89791\tvalidation_1-auc:0.83171                            \n",
      "[24]\tvalidation_0-auc:0.89825\tvalidation_1-auc:0.83164                            \n",
      "[25]\tvalidation_0-auc:0.89910\tvalidation_1-auc:0.83069                            \n",
      "[26]\tvalidation_0-auc:0.89939\tvalidation_1-auc:0.83062                            \n",
      "[0]\tvalidation_0-auc:0.76071\tvalidation_1-auc:0.73015                             \n",
      "[1]\tvalidation_0-auc:0.76423\tvalidation_1-auc:0.73463                             \n",
      "[2]\tvalidation_0-auc:0.77927\tvalidation_1-auc:0.75554                             \n",
      "[3]\tvalidation_0-auc:0.82272\tvalidation_1-auc:0.79619                             \n",
      "[4]\tvalidation_0-auc:0.82108\tvalidation_1-auc:0.79348                             \n",
      "[5]\tvalidation_0-auc:0.83146\tvalidation_1-auc:0.80366                             \n",
      "[6]\tvalidation_0-auc:0.83847\tvalidation_1-auc:0.81073                             \n",
      "[7]\tvalidation_0-auc:0.84339\tvalidation_1-auc:0.81678                             \n",
      "[8]\tvalidation_0-auc:0.84345\tvalidation_1-auc:0.81519                             \n",
      "[9]\tvalidation_0-auc:0.84872\tvalidation_1-auc:0.82009                             \n",
      "[10]\tvalidation_0-auc:0.84816\tvalidation_1-auc:0.81775                            \n",
      "[11]\tvalidation_0-auc:0.85218\tvalidation_1-auc:0.82342                            \n",
      "[12]\tvalidation_0-auc:0.85526\tvalidation_1-auc:0.82509                            \n",
      "[13]\tvalidation_0-auc:0.85493\tvalidation_1-auc:0.82480                            \n",
      "[14]\tvalidation_0-auc:0.85834\tvalidation_1-auc:0.82828                            \n",
      "[15]\tvalidation_0-auc:0.86048\tvalidation_1-auc:0.83164                            \n",
      "[16]\tvalidation_0-auc:0.86198\tvalidation_1-auc:0.83309                            \n",
      "[17]\tvalidation_0-auc:0.86221\tvalidation_1-auc:0.83341                            \n",
      "[18]\tvalidation_0-auc:0.86327\tvalidation_1-auc:0.83365                            \n",
      "[19]\tvalidation_0-auc:0.86388\tvalidation_1-auc:0.83452                            \n",
      "[20]\tvalidation_0-auc:0.86492\tvalidation_1-auc:0.83469                            \n",
      "[21]\tvalidation_0-auc:0.86571\tvalidation_1-auc:0.83479                            \n",
      "[22]\tvalidation_0-auc:0.86682\tvalidation_1-auc:0.83502                            \n",
      "[23]\tvalidation_0-auc:0.86759\tvalidation_1-auc:0.83524                            \n",
      "[24]\tvalidation_0-auc:0.86792\tvalidation_1-auc:0.83544                            \n",
      "[25]\tvalidation_0-auc:0.86807\tvalidation_1-auc:0.83531                            \n",
      "[26]\tvalidation_0-auc:0.86830\tvalidation_1-auc:0.83531                            \n",
      "[27]\tvalidation_0-auc:0.86909\tvalidation_1-auc:0.83560                            \n",
      "[28]\tvalidation_0-auc:0.86995\tvalidation_1-auc:0.83557                            \n",
      "[29]\tvalidation_0-auc:0.87015\tvalidation_1-auc:0.83568                            \n",
      "[0]\tvalidation_0-auc:0.80036\tvalidation_1-auc:0.72694                             \n",
      "[1]\tvalidation_0-auc:0.85950\tvalidation_1-auc:0.80517                             \n",
      "[2]\tvalidation_0-auc:0.85498\tvalidation_1-auc:0.80043                             \n",
      "[3]\tvalidation_0-auc:0.86741\tvalidation_1-auc:0.81312                             \n",
      "[4]\tvalidation_0-auc:0.86606\tvalidation_1-auc:0.81031                             \n",
      "[5]\tvalidation_0-auc:0.87388\tvalidation_1-auc:0.81581                             \n",
      "[6]\tvalidation_0-auc:0.87948\tvalidation_1-auc:0.81916                             \n",
      "[7]\tvalidation_0-auc:0.88211\tvalidation_1-auc:0.82245                             \n",
      "[8]\tvalidation_0-auc:0.88457\tvalidation_1-auc:0.82392                             \n",
      "[9]\tvalidation_0-auc:0.88694\tvalidation_1-auc:0.82564                             \n",
      "[10]\tvalidation_0-auc:0.88950\tvalidation_1-auc:0.82577                            \n",
      "[11]\tvalidation_0-auc:0.89162\tvalidation_1-auc:0.82628                            \n",
      "[12]\tvalidation_0-auc:0.89291\tvalidation_1-auc:0.82691                            \n",
      "[13]\tvalidation_0-auc:0.89395\tvalidation_1-auc:0.82719                            \n",
      "[14]\tvalidation_0-auc:0.89546\tvalidation_1-auc:0.82750                            \n",
      "[15]\tvalidation_0-auc:0.89715\tvalidation_1-auc:0.82832                            \n",
      "[16]\tvalidation_0-auc:0.89758\tvalidation_1-auc:0.82879                            \n",
      "[17]\tvalidation_0-auc:0.89849\tvalidation_1-auc:0.82960                            \n",
      "[18]\tvalidation_0-auc:0.89910\tvalidation_1-auc:0.82991                            \n",
      "[19]\tvalidation_0-auc:0.90033\tvalidation_1-auc:0.82967                            \n",
      "[20]\tvalidation_0-auc:0.90104\tvalidation_1-auc:0.82976                            \n",
      "[21]\tvalidation_0-auc:0.90162\tvalidation_1-auc:0.82969                            \n",
      "[22]\tvalidation_0-auc:0.90211\tvalidation_1-auc:0.83019                            \n",
      "[23]\tvalidation_0-auc:0.90235\tvalidation_1-auc:0.83035                            \n",
      "[24]\tvalidation_0-auc:0.90278\tvalidation_1-auc:0.82966                            \n",
      "[25]\tvalidation_0-auc:0.90333\tvalidation_1-auc:0.82958                            \n",
      "[26]\tvalidation_0-auc:0.90352\tvalidation_1-auc:0.83002                            \n",
      "[27]\tvalidation_0-auc:0.90372\tvalidation_1-auc:0.83002                            \n",
      "[28]\tvalidation_0-auc:0.90455\tvalidation_1-auc:0.83020                            \n",
      "[29]\tvalidation_0-auc:0.90506\tvalidation_1-auc:0.83045                            \n",
      "[0]\tvalidation_0-auc:0.77632\tvalidation_1-auc:0.73302                             \n",
      "[1]\tvalidation_0-auc:0.78344\tvalidation_1-auc:0.74685                             \n",
      "[2]\tvalidation_0-auc:0.78896\tvalidation_1-auc:0.75841                             \n",
      "[3]\tvalidation_0-auc:0.83337\tvalidation_1-auc:0.80019                             \n",
      "[4]\tvalidation_0-auc:0.83163\tvalidation_1-auc:0.79621                             \n",
      "[5]\tvalidation_0-auc:0.84282\tvalidation_1-auc:0.80900                             \n",
      "[6]\tvalidation_0-auc:0.84871\tvalidation_1-auc:0.81651                             \n",
      "[7]\tvalidation_0-auc:0.85309\tvalidation_1-auc:0.81990                             \n",
      "[8]\tvalidation_0-auc:0.85380\tvalidation_1-auc:0.81728                             \n",
      "[9]\tvalidation_0-auc:0.85863\tvalidation_1-auc:0.82205                             \n",
      "[10]\tvalidation_0-auc:0.85836\tvalidation_1-auc:0.82146                            \n",
      "[11]\tvalidation_0-auc:0.86267\tvalidation_1-auc:0.82607                            \n",
      "[12]\tvalidation_0-auc:0.86320\tvalidation_1-auc:0.82534                            \n",
      "[13]\tvalidation_0-auc:0.86327\tvalidation_1-auc:0.82297                            \n",
      "[14]\tvalidation_0-auc:0.86690\tvalidation_1-auc:0.82704                            \n",
      "[15]\tvalidation_0-auc:0.86752\tvalidation_1-auc:0.82636                            \n",
      "[16]\tvalidation_0-auc:0.87053\tvalidation_1-auc:0.82852                            \n",
      "[17]\tvalidation_0-auc:0.87106\tvalidation_1-auc:0.82857                            \n",
      "[18]\tvalidation_0-auc:0.87313\tvalidation_1-auc:0.83059                            \n",
      "[19]\tvalidation_0-auc:0.87498\tvalidation_1-auc:0.83269                            \n",
      "[20]\tvalidation_0-auc:0.87620\tvalidation_1-auc:0.83380                            \n",
      "[21]\tvalidation_0-auc:0.87672\tvalidation_1-auc:0.83375                            \n",
      "[22]\tvalidation_0-auc:0.87813\tvalidation_1-auc:0.83390                            \n",
      "[23]\tvalidation_0-auc:0.87874\tvalidation_1-auc:0.83324                            \n",
      "[24]\tvalidation_0-auc:0.87976\tvalidation_1-auc:0.83368                            \n",
      "[25]\tvalidation_0-auc:0.88080\tvalidation_1-auc:0.83445                            \n",
      "[26]\tvalidation_0-auc:0.88087\tvalidation_1-auc:0.83459                            \n",
      "[27]\tvalidation_0-auc:0.88132\tvalidation_1-auc:0.83453                            \n",
      "[28]\tvalidation_0-auc:0.88146\tvalidation_1-auc:0.83457                            \n",
      "[29]\tvalidation_0-auc:0.88182\tvalidation_1-auc:0.83459                            \n",
      "[0]\tvalidation_0-auc:0.76044\tvalidation_1-auc:0.72967                             \n",
      "[1]\tvalidation_0-auc:0.82967\tvalidation_1-auc:0.80385                             \n",
      "[2]\tvalidation_0-auc:0.81942\tvalidation_1-auc:0.79953                             \n",
      "[3]\tvalidation_0-auc:0.83516\tvalidation_1-auc:0.81356                             \n",
      "[4]\tvalidation_0-auc:0.83083\tvalidation_1-auc:0.80886                             \n",
      "[5]\tvalidation_0-auc:0.83880\tvalidation_1-auc:0.81619                             \n",
      "[6]\tvalidation_0-auc:0.84461\tvalidation_1-auc:0.82263                             \n",
      "[7]\tvalidation_0-auc:0.84856\tvalidation_1-auc:0.82548                             \n",
      "[8]\tvalidation_0-auc:0.84782\tvalidation_1-auc:0.82301                             \n",
      "[9]\tvalidation_0-auc:0.85138\tvalidation_1-auc:0.82494                             \n",
      "[10]\tvalidation_0-auc:0.85310\tvalidation_1-auc:0.82530                            \n",
      "[11]\tvalidation_0-auc:0.85558\tvalidation_1-auc:0.82714                            \n",
      "[12]\tvalidation_0-auc:0.85618\tvalidation_1-auc:0.82775                            \n",
      "[13]\tvalidation_0-auc:0.85765\tvalidation_1-auc:0.82824                            \n",
      "[14]\tvalidation_0-auc:0.85895\tvalidation_1-auc:0.82971                            \n",
      "[15]\tvalidation_0-auc:0.86011\tvalidation_1-auc:0.83047                            \n",
      "[16]\tvalidation_0-auc:0.86123\tvalidation_1-auc:0.83149                            \n",
      "[17]\tvalidation_0-auc:0.86213\tvalidation_1-auc:0.83224                            \n",
      "[18]\tvalidation_0-auc:0.86293\tvalidation_1-auc:0.83277                            \n",
      "[19]\tvalidation_0-auc:0.86413\tvalidation_1-auc:0.83295                            \n",
      "[20]\tvalidation_0-auc:0.86504\tvalidation_1-auc:0.83342                            \n",
      "[21]\tvalidation_0-auc:0.86599\tvalidation_1-auc:0.83336                            \n",
      "[22]\tvalidation_0-auc:0.86673\tvalidation_1-auc:0.83400                            \n",
      "[23]\tvalidation_0-auc:0.86743\tvalidation_1-auc:0.83389                            \n",
      "[24]\tvalidation_0-auc:0.86785\tvalidation_1-auc:0.83439                            \n",
      "[25]\tvalidation_0-auc:0.86830\tvalidation_1-auc:0.83453                            \n",
      "[26]\tvalidation_0-auc:0.86846\tvalidation_1-auc:0.83455                            \n",
      "[27]\tvalidation_0-auc:0.86907\tvalidation_1-auc:0.83438                            \n",
      "[28]\tvalidation_0-auc:0.86983\tvalidation_1-auc:0.83475                            \n",
      "[29]\tvalidation_0-auc:0.87032\tvalidation_1-auc:0.83481                            \n",
      "[0]\tvalidation_0-auc:0.80077\tvalidation_1-auc:0.72614                             \n",
      "[1]\tvalidation_0-auc:0.80693\tvalidation_1-auc:0.73849                             \n",
      "[2]\tvalidation_0-auc:0.81785\tvalidation_1-auc:0.75036                             \n",
      "[3]\tvalidation_0-auc:0.85439\tvalidation_1-auc:0.79164                             \n",
      "[4]\tvalidation_0-auc:0.85368\tvalidation_1-auc:0.79185                             \n",
      "[5]\tvalidation_0-auc:0.86243\tvalidation_1-auc:0.80539                             \n",
      "[6]\tvalidation_0-auc:0.86682\tvalidation_1-auc:0.81101                             \n",
      "[7]\tvalidation_0-auc:0.87049\tvalidation_1-auc:0.81536                             \n",
      "[8]\tvalidation_0-auc:0.87081\tvalidation_1-auc:0.81265                             \n",
      "[9]\tvalidation_0-auc:0.87597\tvalidation_1-auc:0.81716                             \n",
      "[10]\tvalidation_0-auc:0.87625\tvalidation_1-auc:0.81400                            \n",
      "[11]\tvalidation_0-auc:0.87976\tvalidation_1-auc:0.81865                            \n",
      "[12]\tvalidation_0-auc:0.88227\tvalidation_1-auc:0.82179                            \n",
      "[13]\tvalidation_0-auc:0.88234\tvalidation_1-auc:0.82019                            \n",
      "[14]\tvalidation_0-auc:0.88628\tvalidation_1-auc:0.82313                            \n",
      "[15]\tvalidation_0-auc:0.88885\tvalidation_1-auc:0.82591                            \n",
      "[16]\tvalidation_0-auc:0.89011\tvalidation_1-auc:0.82771                            \n",
      "[17]\tvalidation_0-auc:0.89212\tvalidation_1-auc:0.82880                            \n",
      "[18]\tvalidation_0-auc:0.89352\tvalidation_1-auc:0.82946                            \n",
      "[19]\tvalidation_0-auc:0.89481\tvalidation_1-auc:0.83049                            \n",
      "[20]\tvalidation_0-auc:0.89593\tvalidation_1-auc:0.83199                            \n",
      "[21]\tvalidation_0-auc:0.89643\tvalidation_1-auc:0.83186                            \n",
      "[22]\tvalidation_0-auc:0.89802\tvalidation_1-auc:0.83185                            \n",
      "[23]\tvalidation_0-auc:0.89893\tvalidation_1-auc:0.83261                            \n",
      "[24]\tvalidation_0-auc:0.89986\tvalidation_1-auc:0.83226                            \n",
      "[25]\tvalidation_0-auc:0.90083\tvalidation_1-auc:0.83227                            \n",
      "[26]\tvalidation_0-auc:0.90146\tvalidation_1-auc:0.83227                            \n",
      "[27]\tvalidation_0-auc:0.90189\tvalidation_1-auc:0.83253                            \n",
      "[28]\tvalidation_0-auc:0.90292\tvalidation_1-auc:0.83183                            \n",
      "[29]\tvalidation_0-auc:0.90340\tvalidation_1-auc:0.83224                            \n",
      "[0]\tvalidation_0-auc:0.77074\tvalidation_1-auc:0.73384                             \n",
      "[1]\tvalidation_0-auc:0.77795\tvalidation_1-auc:0.74043                             \n",
      "[2]\tvalidation_0-auc:0.78690\tvalidation_1-auc:0.75162                             \n",
      "[3]\tvalidation_0-auc:0.83122\tvalidation_1-auc:0.79702                             \n",
      "[4]\tvalidation_0-auc:0.82968\tvalidation_1-auc:0.79475                             \n",
      "[5]\tvalidation_0-auc:0.84125\tvalidation_1-auc:0.80868                             \n",
      "[6]\tvalidation_0-auc:0.84721\tvalidation_1-auc:0.81633                             \n",
      "[7]\tvalidation_0-auc:0.85200\tvalidation_1-auc:0.82134                             \n",
      "[8]\tvalidation_0-auc:0.85241\tvalidation_1-auc:0.81836                             \n",
      "[9]\tvalidation_0-auc:0.85825\tvalidation_1-auc:0.82317                             \n",
      "[10]\tvalidation_0-auc:0.85664\tvalidation_1-auc:0.82182                            \n",
      "[11]\tvalidation_0-auc:0.86136\tvalidation_1-auc:0.82654                            \n",
      "[12]\tvalidation_0-auc:0.86015\tvalidation_1-auc:0.82487                            \n",
      "[13]\tvalidation_0-auc:0.86013\tvalidation_1-auc:0.82247                            \n",
      "[14]\tvalidation_0-auc:0.86436\tvalidation_1-auc:0.82521                            \n",
      "[15]\tvalidation_0-auc:0.86450\tvalidation_1-auc:0.82458                            \n",
      "[16]\tvalidation_0-auc:0.86718\tvalidation_1-auc:0.82760                            \n",
      "[17]\tvalidation_0-auc:0.86781\tvalidation_1-auc:0.82792                            \n",
      "[18]\tvalidation_0-auc:0.86994\tvalidation_1-auc:0.83017                            \n",
      "[19]\tvalidation_0-auc:0.87182\tvalidation_1-auc:0.83232                            \n",
      "[20]\tvalidation_0-auc:0.87333\tvalidation_1-auc:0.83369                            \n",
      "[21]\tvalidation_0-auc:0.87356\tvalidation_1-auc:0.83346                            \n",
      "[22]\tvalidation_0-auc:0.87520\tvalidation_1-auc:0.83459                            \n",
      "[23]\tvalidation_0-auc:0.87558\tvalidation_1-auc:0.83418                            \n",
      "[24]\tvalidation_0-auc:0.87671\tvalidation_1-auc:0.83518                            \n",
      "[25]\tvalidation_0-auc:0.87715\tvalidation_1-auc:0.83607                            \n",
      "[26]\tvalidation_0-auc:0.87821\tvalidation_1-auc:0.83604                            \n",
      "[27]\tvalidation_0-auc:0.87903\tvalidation_1-auc:0.83612                            \n",
      "[28]\tvalidation_0-auc:0.87958\tvalidation_1-auc:0.83634                            \n",
      "[29]\tvalidation_0-auc:0.87997\tvalidation_1-auc:0.83610                            \n",
      "[0]\tvalidation_0-auc:0.79608\tvalidation_1-auc:0.74220                             \n",
      "[1]\tvalidation_0-auc:0.81201\tvalidation_1-auc:0.74694                             \n",
      "[2]\tvalidation_0-auc:0.81547\tvalidation_1-auc:0.75182                             \n",
      "[3]\tvalidation_0-auc:0.85583\tvalidation_1-auc:0.79650                             \n",
      "[4]\tvalidation_0-auc:0.85364\tvalidation_1-auc:0.79782                             \n",
      "[5]\tvalidation_0-auc:0.86274\tvalidation_1-auc:0.80936                             \n",
      "[6]\tvalidation_0-auc:0.86717\tvalidation_1-auc:0.81915                             \n",
      "[7]\tvalidation_0-auc:0.86630\tvalidation_1-auc:0.81563                             \n",
      "[8]\tvalidation_0-auc:0.86626\tvalidation_1-auc:0.81322                             \n",
      "[9]\tvalidation_0-auc:0.87235\tvalidation_1-auc:0.81963                             \n",
      "[10]\tvalidation_0-auc:0.87247\tvalidation_1-auc:0.81546                            \n",
      "[11]\tvalidation_0-auc:0.87887\tvalidation_1-auc:0.82073                            \n",
      "[12]\tvalidation_0-auc:0.87834\tvalidation_1-auc:0.82022                            \n",
      "[13]\tvalidation_0-auc:0.87934\tvalidation_1-auc:0.82033                            \n",
      "[14]\tvalidation_0-auc:0.88031\tvalidation_1-auc:0.81883                            \n",
      "[15]\tvalidation_0-auc:0.88024\tvalidation_1-auc:0.81709                            \n",
      "[16]\tvalidation_0-auc:0.88157\tvalidation_1-auc:0.81644                            \n",
      "[17]\tvalidation_0-auc:0.88268\tvalidation_1-auc:0.81544                            \n",
      "[18]\tvalidation_0-auc:0.88806\tvalidation_1-auc:0.82156                            \n",
      "[19]\tvalidation_0-auc:0.89182\tvalidation_1-auc:0.82504                            \n",
      "[20]\tvalidation_0-auc:0.89431\tvalidation_1-auc:0.82810                            \n",
      "[21]\tvalidation_0-auc:0.89439\tvalidation_1-auc:0.82691                            \n",
      "[22]\tvalidation_0-auc:0.89547\tvalidation_1-auc:0.82688                            \n",
      "[23]\tvalidation_0-auc:0.89751\tvalidation_1-auc:0.82630                            \n",
      "[24]\tvalidation_0-auc:0.89995\tvalidation_1-auc:0.82963                            \n",
      "[25]\tvalidation_0-auc:0.90148\tvalidation_1-auc:0.83090                            \n",
      "[26]\tvalidation_0-auc:0.90363\tvalidation_1-auc:0.83204                            \n",
      "[27]\tvalidation_0-auc:0.90542\tvalidation_1-auc:0.83285                            \n",
      "[28]\tvalidation_0-auc:0.90576\tvalidation_1-auc:0.83244                            \n",
      "[29]\tvalidation_0-auc:0.90578\tvalidation_1-auc:0.83244                            \n",
      "[0]\tvalidation_0-auc:0.77074\tvalidation_1-auc:0.73384                             \n",
      "[1]\tvalidation_0-auc:0.77813\tvalidation_1-auc:0.73965                             \n",
      "[2]\tvalidation_0-auc:0.78707\tvalidation_1-auc:0.75129                             \n",
      "[3]\tvalidation_0-auc:0.83342\tvalidation_1-auc:0.80015                             \n",
      "[4]\tvalidation_0-auc:0.83093\tvalidation_1-auc:0.79755                             \n",
      "[5]\tvalidation_0-auc:0.84255\tvalidation_1-auc:0.81045                             \n",
      "[6]\tvalidation_0-auc:0.84880\tvalidation_1-auc:0.81986                             \n",
      "[7]\tvalidation_0-auc:0.85396\tvalidation_1-auc:0.82317                             \n",
      "[8]\tvalidation_0-auc:0.85452\tvalidation_1-auc:0.82055                             \n",
      "[9]\tvalidation_0-auc:0.86090\tvalidation_1-auc:0.82534                             \n",
      "[10]\tvalidation_0-auc:0.86005\tvalidation_1-auc:0.82423                            \n",
      "[11]\tvalidation_0-auc:0.86512\tvalidation_1-auc:0.82876                            \n",
      "[12]\tvalidation_0-auc:0.86495\tvalidation_1-auc:0.82750                            \n",
      "[13]\tvalidation_0-auc:0.86560\tvalidation_1-auc:0.82578                            \n",
      "[14]\tvalidation_0-auc:0.86960\tvalidation_1-auc:0.82942                            \n",
      "[15]\tvalidation_0-auc:0.86954\tvalidation_1-auc:0.82761                            \n",
      "[16]\tvalidation_0-auc:0.87217\tvalidation_1-auc:0.83037                            \n",
      "[17]\tvalidation_0-auc:0.87246\tvalidation_1-auc:0.83019                            \n",
      "[18]\tvalidation_0-auc:0.87482\tvalidation_1-auc:0.83202                            \n",
      "[19]\tvalidation_0-auc:0.87581\tvalidation_1-auc:0.83348                            \n",
      "[20]\tvalidation_0-auc:0.87728\tvalidation_1-auc:0.83418                            \n",
      "[21]\tvalidation_0-auc:0.87838\tvalidation_1-auc:0.83381                            \n",
      "[22]\tvalidation_0-auc:0.87930\tvalidation_1-auc:0.83483                            \n",
      "[23]\tvalidation_0-auc:0.87985\tvalidation_1-auc:0.83451                            \n",
      "[24]\tvalidation_0-auc:0.88066\tvalidation_1-auc:0.83515                            \n",
      "[25]\tvalidation_0-auc:0.88093\tvalidation_1-auc:0.83563                            \n",
      "[26]\tvalidation_0-auc:0.88207\tvalidation_1-auc:0.83515                            \n",
      "[27]\tvalidation_0-auc:0.88267\tvalidation_1-auc:0.83472                            \n",
      "[28]\tvalidation_0-auc:0.88285\tvalidation_1-auc:0.83442                            \n",
      "[29]\tvalidation_0-auc:0.88305\tvalidation_1-auc:0.83427                            \n",
      "[0]\tvalidation_0-auc:0.79099\tvalidation_1-auc:0.73661                             \n",
      "[1]\tvalidation_0-auc:0.80353\tvalidation_1-auc:0.75030                             \n",
      "[2]\tvalidation_0-auc:0.80656\tvalidation_1-auc:0.75462                             \n",
      "[3]\tvalidation_0-auc:0.85011\tvalidation_1-auc:0.79699                             \n",
      "[4]\tvalidation_0-auc:0.84747\tvalidation_1-auc:0.79828                             \n",
      "[5]\tvalidation_0-auc:0.85578\tvalidation_1-auc:0.80906                             \n",
      "[6]\tvalidation_0-auc:0.86049\tvalidation_1-auc:0.81740                             \n",
      "[7]\tvalidation_0-auc:0.85933\tvalidation_1-auc:0.81413                             \n",
      "[8]\tvalidation_0-auc:0.85993\tvalidation_1-auc:0.81147                             \n",
      "[9]\tvalidation_0-auc:0.86541\tvalidation_1-auc:0.81613                             \n",
      "[10]\tvalidation_0-auc:0.86466\tvalidation_1-auc:0.81379                            \n",
      "[11]\tvalidation_0-auc:0.86870\tvalidation_1-auc:0.81962                            \n",
      "[12]\tvalidation_0-auc:0.86802\tvalidation_1-auc:0.81791                            \n",
      "[13]\tvalidation_0-auc:0.86875\tvalidation_1-auc:0.81758                            \n",
      "[14]\tvalidation_0-auc:0.86873\tvalidation_1-auc:0.81669                            \n",
      "[15]\tvalidation_0-auc:0.86855\tvalidation_1-auc:0.81497                            \n",
      "[16]\tvalidation_0-auc:0.87009\tvalidation_1-auc:0.81429                            \n",
      "[17]\tvalidation_0-auc:0.87087\tvalidation_1-auc:0.81346                            \n",
      "[18]\tvalidation_0-auc:0.87570\tvalidation_1-auc:0.81887                            \n",
      "[19]\tvalidation_0-auc:0.87910\tvalidation_1-auc:0.82285                            \n",
      "[20]\tvalidation_0-auc:0.88229\tvalidation_1-auc:0.82595                            \n",
      "[21]\tvalidation_0-auc:0.88172\tvalidation_1-auc:0.82487                            \n",
      "[22]\tvalidation_0-auc:0.88244\tvalidation_1-auc:0.82388                            \n",
      "[23]\tvalidation_0-auc:0.88289\tvalidation_1-auc:0.82277                            \n",
      "[24]\tvalidation_0-auc:0.88630\tvalidation_1-auc:0.82618                            \n",
      "[25]\tvalidation_0-auc:0.88803\tvalidation_1-auc:0.82867                            \n",
      "[26]\tvalidation_0-auc:0.89001\tvalidation_1-auc:0.83000                            \n",
      "[27]\tvalidation_0-auc:0.89144\tvalidation_1-auc:0.83156                            \n",
      "[28]\tvalidation_0-auc:0.89238\tvalidation_1-auc:0.83144                            \n",
      "[29]\tvalidation_0-auc:0.89251\tvalidation_1-auc:0.83110                            \n",
      "[0]\tvalidation_0-auc:0.78443\tvalidation_1-auc:0.73787                             \n",
      "[1]\tvalidation_0-auc:0.79577\tvalidation_1-auc:0.74829                             \n",
      "[2]\tvalidation_0-auc:0.80159\tvalidation_1-auc:0.75517                             \n",
      "[3]\tvalidation_0-auc:0.84445\tvalidation_1-auc:0.80011                             \n",
      "[4]\tvalidation_0-auc:0.84206\tvalidation_1-auc:0.79920                             \n",
      "[5]\tvalidation_0-auc:0.85301\tvalidation_1-auc:0.81152                             \n",
      "[6]\tvalidation_0-auc:0.85893\tvalidation_1-auc:0.82025                             \n",
      "[7]\tvalidation_0-auc:0.86329\tvalidation_1-auc:0.82425                             \n",
      "[8]\tvalidation_0-auc:0.86335\tvalidation_1-auc:0.82151                             \n",
      "[9]\tvalidation_0-auc:0.86914\tvalidation_1-auc:0.82613                             \n",
      "[10]\tvalidation_0-auc:0.86889\tvalidation_1-auc:0.82307                            \n",
      "[11]\tvalidation_0-auc:0.87372\tvalidation_1-auc:0.82933                            \n",
      "[12]\tvalidation_0-auc:0.87383\tvalidation_1-auc:0.82775                            \n",
      "[13]\tvalidation_0-auc:0.87403\tvalidation_1-auc:0.82676                            \n",
      "[14]\tvalidation_0-auc:0.87798\tvalidation_1-auc:0.83037                            \n",
      "[15]\tvalidation_0-auc:0.87810\tvalidation_1-auc:0.82855                            \n",
      "[16]\tvalidation_0-auc:0.88071\tvalidation_1-auc:0.83120                            \n",
      "[17]\tvalidation_0-auc:0.88158\tvalidation_1-auc:0.82985                            \n",
      "[18]\tvalidation_0-auc:0.88395\tvalidation_1-auc:0.83142                            \n",
      "[19]\tvalidation_0-auc:0.88532\tvalidation_1-auc:0.83248                            \n",
      "[20]\tvalidation_0-auc:0.88692\tvalidation_1-auc:0.83302                            \n",
      "[21]\tvalidation_0-auc:0.88721\tvalidation_1-auc:0.83289                            \n",
      "[22]\tvalidation_0-auc:0.88849\tvalidation_1-auc:0.83375                            \n",
      "[23]\tvalidation_0-auc:0.88936\tvalidation_1-auc:0.83375                            \n",
      "[24]\tvalidation_0-auc:0.89029\tvalidation_1-auc:0.83448                            \n",
      "[25]\tvalidation_0-auc:0.89063\tvalidation_1-auc:0.83507                            \n",
      "[26]\tvalidation_0-auc:0.89105\tvalidation_1-auc:0.83486                            \n",
      "[27]\tvalidation_0-auc:0.89159\tvalidation_1-auc:0.83439                            \n",
      "[28]\tvalidation_0-auc:0.89223\tvalidation_1-auc:0.83403                            \n",
      "[29]\tvalidation_0-auc:0.89250\tvalidation_1-auc:0.83400                            \n",
      "[0]\tvalidation_0-auc:0.77345\tvalidation_1-auc:0.73963                             \n",
      "[1]\tvalidation_0-auc:0.78432\tvalidation_1-auc:0.75211                             \n",
      "[2]\tvalidation_0-auc:0.78747\tvalidation_1-auc:0.75414                             \n",
      "[3]\tvalidation_0-auc:0.82955\tvalidation_1-auc:0.79662                             \n",
      "[4]\tvalidation_0-auc:0.82569\tvalidation_1-auc:0.79345                             \n",
      "[5]\tvalidation_0-auc:0.83638\tvalidation_1-auc:0.80468                             \n",
      "[6]\tvalidation_0-auc:0.84184\tvalidation_1-auc:0.81328                             \n",
      "[7]\tvalidation_0-auc:0.83912\tvalidation_1-auc:0.81055                             \n",
      "[8]\tvalidation_0-auc:0.84072\tvalidation_1-auc:0.80911                             \n",
      "[9]\tvalidation_0-auc:0.84635\tvalidation_1-auc:0.81448                             \n",
      "[10]\tvalidation_0-auc:0.84564\tvalidation_1-auc:0.81154                            \n",
      "[11]\tvalidation_0-auc:0.85003\tvalidation_1-auc:0.81714                            \n",
      "[12]\tvalidation_0-auc:0.84880\tvalidation_1-auc:0.81519                            \n",
      "[13]\tvalidation_0-auc:0.84915\tvalidation_1-auc:0.81337                            \n",
      "[14]\tvalidation_0-auc:0.84936\tvalidation_1-auc:0.81153                            \n",
      "[15]\tvalidation_0-auc:0.84970\tvalidation_1-auc:0.81031                            \n",
      "[16]\tvalidation_0-auc:0.85330\tvalidation_1-auc:0.81402                            \n",
      "[17]\tvalidation_0-auc:0.85340\tvalidation_1-auc:0.81475                            \n",
      "[18]\tvalidation_0-auc:0.85613\tvalidation_1-auc:0.81829                            \n",
      "[19]\tvalidation_0-auc:0.85913\tvalidation_1-auc:0.82165                            \n",
      "[20]\tvalidation_0-auc:0.86178\tvalidation_1-auc:0.82490                            \n",
      "[21]\tvalidation_0-auc:0.86140\tvalidation_1-auc:0.82412                            \n",
      "[22]\tvalidation_0-auc:0.86384\tvalidation_1-auc:0.82663                            \n",
      "[23]\tvalidation_0-auc:0.86382\tvalidation_1-auc:0.82649                            \n",
      "[24]\tvalidation_0-auc:0.86618\tvalidation_1-auc:0.82865                            \n",
      "[25]\tvalidation_0-auc:0.86752\tvalidation_1-auc:0.83058                            \n",
      "[26]\tvalidation_0-auc:0.86927\tvalidation_1-auc:0.83210                            \n",
      "[27]\tvalidation_0-auc:0.87037\tvalidation_1-auc:0.83382                            \n",
      "[28]\tvalidation_0-auc:0.87083\tvalidation_1-auc:0.83388                            \n",
      "[29]\tvalidation_0-auc:0.87092\tvalidation_1-auc:0.83343                            \n",
      "[0]\tvalidation_0-auc:0.80803\tvalidation_1-auc:0.73198                             \n",
      "[1]\tvalidation_0-auc:0.81997\tvalidation_1-auc:0.74078                             \n",
      "[2]\tvalidation_0-auc:0.83011\tvalidation_1-auc:0.75182                             \n",
      "[3]\tvalidation_0-auc:0.86757\tvalidation_1-auc:0.79214                             \n",
      "[4]\tvalidation_0-auc:0.86668\tvalidation_1-auc:0.78960                             \n",
      "[5]\tvalidation_0-auc:0.87625\tvalidation_1-auc:0.80331                             \n",
      "[6]\tvalidation_0-auc:0.88400\tvalidation_1-auc:0.81241                             \n",
      "[7]\tvalidation_0-auc:0.88784\tvalidation_1-auc:0.81674                             \n",
      "[8]\tvalidation_0-auc:0.89019\tvalidation_1-auc:0.81249                             \n",
      "[9]\tvalidation_0-auc:0.89507\tvalidation_1-auc:0.81931                             \n",
      "[10]\tvalidation_0-auc:0.89588\tvalidation_1-auc:0.81640                            \n",
      "[11]\tvalidation_0-auc:0.90229\tvalidation_1-auc:0.82018                            \n",
      "[12]\tvalidation_0-auc:0.90234\tvalidation_1-auc:0.81787                            \n",
      "[13]\tvalidation_0-auc:0.90254\tvalidation_1-auc:0.81514                            \n",
      "[14]\tvalidation_0-auc:0.90679\tvalidation_1-auc:0.81832                            \n",
      "[15]\tvalidation_0-auc:0.90774\tvalidation_1-auc:0.81702                            \n",
      "[16]\tvalidation_0-auc:0.91031\tvalidation_1-auc:0.82012                            \n",
      "[17]\tvalidation_0-auc:0.91163\tvalidation_1-auc:0.81899                            \n",
      "[18]\tvalidation_0-auc:0.91441\tvalidation_1-auc:0.82187                            \n",
      "[19]\tvalidation_0-auc:0.91646\tvalidation_1-auc:0.82404                            \n",
      "[20]\tvalidation_0-auc:0.91868\tvalidation_1-auc:0.82532                            \n",
      "[21]\tvalidation_0-auc:0.91939\tvalidation_1-auc:0.82453                            \n",
      "[22]\tvalidation_0-auc:0.92072\tvalidation_1-auc:0.82558                            \n",
      "[23]\tvalidation_0-auc:0.92075\tvalidation_1-auc:0.82544                            \n",
      "[24]\tvalidation_0-auc:0.92194\tvalidation_1-auc:0.82568                            \n",
      "[25]\tvalidation_0-auc:0.92278\tvalidation_1-auc:0.82706                            \n",
      "[26]\tvalidation_0-auc:0.92347\tvalidation_1-auc:0.82757                            \n",
      "[27]\tvalidation_0-auc:0.92443\tvalidation_1-auc:0.82752                            \n",
      "[28]\tvalidation_0-auc:0.92519\tvalidation_1-auc:0.82720                            \n",
      "[29]\tvalidation_0-auc:0.92615\tvalidation_1-auc:0.82608                            \n",
      "[0]\tvalidation_0-auc:0.78441\tvalidation_1-auc:0.73723                             \n",
      "[1]\tvalidation_0-auc:0.79474\tvalidation_1-auc:0.75467                             \n",
      "[2]\tvalidation_0-auc:0.79909\tvalidation_1-auc:0.75655                             \n",
      "[3]\tvalidation_0-auc:0.84244\tvalidation_1-auc:0.79893                             \n",
      "[4]\tvalidation_0-auc:0.84071\tvalidation_1-auc:0.79724                             \n",
      "[5]\tvalidation_0-auc:0.84968\tvalidation_1-auc:0.80760                             \n",
      "[6]\tvalidation_0-auc:0.85448\tvalidation_1-auc:0.81718                             \n",
      "[7]\tvalidation_0-auc:0.85366\tvalidation_1-auc:0.81383                             \n",
      "[8]\tvalidation_0-auc:0.85446\tvalidation_1-auc:0.81100                             \n",
      "[9]\tvalidation_0-auc:0.86090\tvalidation_1-auc:0.81760                             \n",
      "[10]\tvalidation_0-auc:0.86161\tvalidation_1-auc:0.81385                            \n",
      "[11]\tvalidation_0-auc:0.86720\tvalidation_1-auc:0.82109                            \n",
      "[12]\tvalidation_0-auc:0.86699\tvalidation_1-auc:0.81937                            \n",
      "[13]\tvalidation_0-auc:0.86711\tvalidation_1-auc:0.81822                            \n",
      "[14]\tvalidation_0-auc:0.86927\tvalidation_1-auc:0.81700                            \n",
      "[15]\tvalidation_0-auc:0.86923\tvalidation_1-auc:0.81546                            \n",
      "[16]\tvalidation_0-auc:0.87042\tvalidation_1-auc:0.81563                            \n",
      "[17]\tvalidation_0-auc:0.87152\tvalidation_1-auc:0.81473                            \n",
      "[18]\tvalidation_0-auc:0.87596\tvalidation_1-auc:0.82034                            \n",
      "[19]\tvalidation_0-auc:0.87906\tvalidation_1-auc:0.82495                            \n",
      "[20]\tvalidation_0-auc:0.88221\tvalidation_1-auc:0.82807                            \n",
      "[21]\tvalidation_0-auc:0.88295\tvalidation_1-auc:0.82727                            \n",
      "[22]\tvalidation_0-auc:0.88375\tvalidation_1-auc:0.82739                            \n",
      "[23]\tvalidation_0-auc:0.88408\tvalidation_1-auc:0.82664                            \n",
      "[24]\tvalidation_0-auc:0.88683\tvalidation_1-auc:0.82920                            \n",
      "[25]\tvalidation_0-auc:0.88813\tvalidation_1-auc:0.83157                            \n",
      "[26]\tvalidation_0-auc:0.88906\tvalidation_1-auc:0.83248                            \n",
      "[27]\tvalidation_0-auc:0.89005\tvalidation_1-auc:0.83311                            \n",
      "[28]\tvalidation_0-auc:0.89019\tvalidation_1-auc:0.83269                            \n",
      "[29]\tvalidation_0-auc:0.89047\tvalidation_1-auc:0.83275                            \n",
      "[0]\tvalidation_0-auc:0.81185\tvalidation_1-auc:0.72923                             \n",
      "[1]\tvalidation_0-auc:0.82332\tvalidation_1-auc:0.73936                             \n",
      "[2]\tvalidation_0-auc:0.83128\tvalidation_1-auc:0.74601                             \n",
      "[3]\tvalidation_0-auc:0.87408\tvalidation_1-auc:0.79066                             \n",
      "[4]\tvalidation_0-auc:0.87218\tvalidation_1-auc:0.78921                             \n",
      "[5]\tvalidation_0-auc:0.87957\tvalidation_1-auc:0.80423                             \n",
      "[6]\tvalidation_0-auc:0.88398\tvalidation_1-auc:0.81013                             \n",
      "[7]\tvalidation_0-auc:0.88828\tvalidation_1-auc:0.81426                             \n",
      "[8]\tvalidation_0-auc:0.88996\tvalidation_1-auc:0.81140                             \n",
      "[9]\tvalidation_0-auc:0.89494\tvalidation_1-auc:0.81580                             \n",
      "[10]\tvalidation_0-auc:0.89559\tvalidation_1-auc:0.81200                            \n",
      "[11]\tvalidation_0-auc:0.90015\tvalidation_1-auc:0.81589                            \n",
      "[12]\tvalidation_0-auc:0.89952\tvalidation_1-auc:0.81335                            \n",
      "[13]\tvalidation_0-auc:0.89975\tvalidation_1-auc:0.81227                            \n",
      "[14]\tvalidation_0-auc:0.90412\tvalidation_1-auc:0.81589                            \n",
      "[15]\tvalidation_0-auc:0.90522\tvalidation_1-auc:0.81478                            \n",
      "[16]\tvalidation_0-auc:0.90762\tvalidation_1-auc:0.81802                            \n",
      "[17]\tvalidation_0-auc:0.90812\tvalidation_1-auc:0.81712                            \n",
      "[18]\tvalidation_0-auc:0.91027\tvalidation_1-auc:0.82007                            \n",
      "[19]\tvalidation_0-auc:0.91232\tvalidation_1-auc:0.82232                            \n",
      "[20]\tvalidation_0-auc:0.91465\tvalidation_1-auc:0.82241                            \n",
      "[21]\tvalidation_0-auc:0.91475\tvalidation_1-auc:0.82115                            \n",
      "[22]\tvalidation_0-auc:0.91697\tvalidation_1-auc:0.82247                            \n",
      "[23]\tvalidation_0-auc:0.91830\tvalidation_1-auc:0.82231                            \n",
      "[24]\tvalidation_0-auc:0.91994\tvalidation_1-auc:0.82390                            \n",
      "[25]\tvalidation_0-auc:0.92119\tvalidation_1-auc:0.82487                            \n",
      "[26]\tvalidation_0-auc:0.92204\tvalidation_1-auc:0.82593                            \n",
      "[27]\tvalidation_0-auc:0.92319\tvalidation_1-auc:0.82651                            \n",
      "[28]\tvalidation_0-auc:0.92401\tvalidation_1-auc:0.82661                            \n",
      "[29]\tvalidation_0-auc:0.92466\tvalidation_1-auc:0.82621                            \n",
      "[0]\tvalidation_0-auc:0.76833\tvalidation_1-auc:0.73031                             \n",
      "[1]\tvalidation_0-auc:0.78247\tvalidation_1-auc:0.75038                             \n",
      "[2]\tvalidation_0-auc:0.78652\tvalidation_1-auc:0.75151                             \n",
      "[3]\tvalidation_0-auc:0.83058\tvalidation_1-auc:0.79464                             \n",
      "[4]\tvalidation_0-auc:0.82989\tvalidation_1-auc:0.79553                             \n",
      "[5]\tvalidation_0-auc:0.84009\tvalidation_1-auc:0.80554                             \n",
      "[6]\tvalidation_0-auc:0.84657\tvalidation_1-auc:0.81570                             \n",
      "[7]\tvalidation_0-auc:0.84369\tvalidation_1-auc:0.81269                             \n",
      "[8]\tvalidation_0-auc:0.84608\tvalidation_1-auc:0.81104                             \n",
      "[9]\tvalidation_0-auc:0.85370\tvalidation_1-auc:0.81843                             \n",
      "[10]\tvalidation_0-auc:0.85276\tvalidation_1-auc:0.81610                            \n",
      "[11]\tvalidation_0-auc:0.85835\tvalidation_1-auc:0.82461                            \n",
      "[12]\tvalidation_0-auc:0.85752\tvalidation_1-auc:0.82243                            \n",
      "[13]\tvalidation_0-auc:0.85910\tvalidation_1-auc:0.82134                            \n",
      "[14]\tvalidation_0-auc:0.85964\tvalidation_1-auc:0.81929                            \n",
      "[15]\tvalidation_0-auc:0.86008\tvalidation_1-auc:0.81771                            \n",
      "[16]\tvalidation_0-auc:0.86455\tvalidation_1-auc:0.82369                            \n",
      "[17]\tvalidation_0-auc:0.86559\tvalidation_1-auc:0.82278                            \n",
      "[18]\tvalidation_0-auc:0.86984\tvalidation_1-auc:0.82740                            \n",
      "[19]\tvalidation_0-auc:0.87268\tvalidation_1-auc:0.83063                            \n",
      "[20]\tvalidation_0-auc:0.87457\tvalidation_1-auc:0.83289                            \n",
      "[21]\tvalidation_0-auc:0.87521\tvalidation_1-auc:0.83210                            \n",
      "[22]\tvalidation_0-auc:0.87807\tvalidation_1-auc:0.83382                            \n",
      "[23]\tvalidation_0-auc:0.87962\tvalidation_1-auc:0.83214                            \n",
      "[24]\tvalidation_0-auc:0.88176\tvalidation_1-auc:0.83308                            \n",
      "[25]\tvalidation_0-auc:0.88308\tvalidation_1-auc:0.83358                            \n",
      "[26]\tvalidation_0-auc:0.88408\tvalidation_1-auc:0.83410                            \n",
      "[27]\tvalidation_0-auc:0.88509\tvalidation_1-auc:0.83479                            \n",
      "[28]\tvalidation_0-auc:0.88545\tvalidation_1-auc:0.83483                            \n",
      "[29]\tvalidation_0-auc:0.88568\tvalidation_1-auc:0.83497                            \n",
      "[0]\tvalidation_0-auc:0.76074\tvalidation_1-auc:0.73004                             \n",
      "[1]\tvalidation_0-auc:0.76418\tvalidation_1-auc:0.73501                             \n",
      "[2]\tvalidation_0-auc:0.77322\tvalidation_1-auc:0.74204                             \n",
      "[3]\tvalidation_0-auc:0.82238\tvalidation_1-auc:0.79570                             \n",
      "[4]\tvalidation_0-auc:0.82073\tvalidation_1-auc:0.79204                             \n",
      "[5]\tvalidation_0-auc:0.83102\tvalidation_1-auc:0.80258                             \n",
      "[6]\tvalidation_0-auc:0.83603\tvalidation_1-auc:0.81056                             \n",
      "[7]\tvalidation_0-auc:0.84202\tvalidation_1-auc:0.81818                             \n",
      "[8]\tvalidation_0-auc:0.84179\tvalidation_1-auc:0.81583                             \n",
      "[9]\tvalidation_0-auc:0.84686\tvalidation_1-auc:0.82223                             \n",
      "[10]\tvalidation_0-auc:0.84512\tvalidation_1-auc:0.81778                            \n",
      "[11]\tvalidation_0-auc:0.84991\tvalidation_1-auc:0.82277                            \n",
      "[12]\tvalidation_0-auc:0.84848\tvalidation_1-auc:0.82085                            \n",
      "[13]\tvalidation_0-auc:0.84879\tvalidation_1-auc:0.81964                            \n",
      "[14]\tvalidation_0-auc:0.85315\tvalidation_1-auc:0.82382                            \n",
      "[15]\tvalidation_0-auc:0.85260\tvalidation_1-auc:0.82352                            \n",
      "[16]\tvalidation_0-auc:0.85544\tvalidation_1-auc:0.82641                            \n",
      "[17]\tvalidation_0-auc:0.85567\tvalidation_1-auc:0.82656                            \n",
      "[18]\tvalidation_0-auc:0.85762\tvalidation_1-auc:0.82854                            \n",
      "[19]\tvalidation_0-auc:0.85994\tvalidation_1-auc:0.83107                            \n",
      "[20]\tvalidation_0-auc:0.86173\tvalidation_1-auc:0.83291                            \n",
      "[21]\tvalidation_0-auc:0.86231\tvalidation_1-auc:0.83160                            \n",
      "[22]\tvalidation_0-auc:0.86373\tvalidation_1-auc:0.83220                            \n",
      "[23]\tvalidation_0-auc:0.86436\tvalidation_1-auc:0.83257                            \n",
      "[24]\tvalidation_0-auc:0.86519\tvalidation_1-auc:0.83348                            \n",
      "[25]\tvalidation_0-auc:0.86608\tvalidation_1-auc:0.83430                            \n",
      "[26]\tvalidation_0-auc:0.86703\tvalidation_1-auc:0.83535                            \n",
      "[27]\tvalidation_0-auc:0.86778\tvalidation_1-auc:0.83563                            \n",
      "[28]\tvalidation_0-auc:0.86839\tvalidation_1-auc:0.83564                            \n",
      "[29]\tvalidation_0-auc:0.86893\tvalidation_1-auc:0.83555                            \n",
      "[0]\tvalidation_0-auc:0.79969\tvalidation_1-auc:0.73592                             \n",
      "[1]\tvalidation_0-auc:0.81539\tvalidation_1-auc:0.74605                             \n",
      "[2]\tvalidation_0-auc:0.81645\tvalidation_1-auc:0.75429                             \n",
      "[3]\tvalidation_0-auc:0.85749\tvalidation_1-auc:0.79708                             \n",
      "[4]\tvalidation_0-auc:0.85553\tvalidation_1-auc:0.79412                             \n",
      "[5]\tvalidation_0-auc:0.86347\tvalidation_1-auc:0.80766                             \n",
      "[6]\tvalidation_0-auc:0.86812\tvalidation_1-auc:0.81725                             \n",
      "[7]\tvalidation_0-auc:0.86687\tvalidation_1-auc:0.81317                             \n",
      "[8]\tvalidation_0-auc:0.86784\tvalidation_1-auc:0.81124                             \n",
      "[9]\tvalidation_0-auc:0.87414\tvalidation_1-auc:0.81700                             \n",
      "[10]\tvalidation_0-auc:0.87406\tvalidation_1-auc:0.81473                            \n",
      "[11]\tvalidation_0-auc:0.87822\tvalidation_1-auc:0.81961                            \n",
      "[12]\tvalidation_0-auc:0.87768\tvalidation_1-auc:0.81705                            \n",
      "[13]\tvalidation_0-auc:0.87867\tvalidation_1-auc:0.81695                            \n",
      "[14]\tvalidation_0-auc:0.87842\tvalidation_1-auc:0.81567                            \n",
      "[15]\tvalidation_0-auc:0.87790\tvalidation_1-auc:0.81531                            \n",
      "[16]\tvalidation_0-auc:0.87944\tvalidation_1-auc:0.81409                            \n",
      "[17]\tvalidation_0-auc:0.88085\tvalidation_1-auc:0.81289                            \n",
      "[18]\tvalidation_0-auc:0.88530\tvalidation_1-auc:0.81736                            \n",
      "[19]\tvalidation_0-auc:0.88905\tvalidation_1-auc:0.82165                            \n",
      "[20]\tvalidation_0-auc:0.89161\tvalidation_1-auc:0.82458                            \n",
      "[21]\tvalidation_0-auc:0.89159\tvalidation_1-auc:0.82316                            \n",
      "[22]\tvalidation_0-auc:0.89248\tvalidation_1-auc:0.82279                            \n",
      "[23]\tvalidation_0-auc:0.89316\tvalidation_1-auc:0.82189                            \n",
      "[24]\tvalidation_0-auc:0.89701\tvalidation_1-auc:0.82348                            \n",
      "[25]\tvalidation_0-auc:0.89896\tvalidation_1-auc:0.82616                            \n",
      "[26]\tvalidation_0-auc:0.89965\tvalidation_1-auc:0.82581                            \n",
      "[27]\tvalidation_0-auc:0.90174\tvalidation_1-auc:0.82740                            \n",
      "[28]\tvalidation_0-auc:0.90248\tvalidation_1-auc:0.82704                            \n",
      "[29]\tvalidation_0-auc:0.90282\tvalidation_1-auc:0.82639                            \n",
      "[0]\tvalidation_0-auc:0.80566\tvalidation_1-auc:0.73782                             \n",
      "[1]\tvalidation_0-auc:0.81780\tvalidation_1-auc:0.74291                             \n",
      "[2]\tvalidation_0-auc:0.83212\tvalidation_1-auc:0.74474                             \n",
      "[3]\tvalidation_0-auc:0.86948\tvalidation_1-auc:0.79103                             \n",
      "[4]\tvalidation_0-auc:0.86867\tvalidation_1-auc:0.78806                             \n",
      "[5]\tvalidation_0-auc:0.87814\tvalidation_1-auc:0.80592                             \n",
      "[6]\tvalidation_0-auc:0.88728\tvalidation_1-auc:0.81116                             \n",
      "[7]\tvalidation_0-auc:0.89163\tvalidation_1-auc:0.81686                             \n",
      "[8]\tvalidation_0-auc:0.89262\tvalidation_1-auc:0.81363                             \n",
      "[9]\tvalidation_0-auc:0.89910\tvalidation_1-auc:0.82039                             \n",
      "[10]\tvalidation_0-auc:0.90124\tvalidation_1-auc:0.81865                            \n",
      "[11]\tvalidation_0-auc:0.90572\tvalidation_1-auc:0.82290                            \n",
      "[12]\tvalidation_0-auc:0.90600\tvalidation_1-auc:0.82186                            \n",
      "[13]\tvalidation_0-auc:0.90688\tvalidation_1-auc:0.82152                            \n",
      "[14]\tvalidation_0-auc:0.91139\tvalidation_1-auc:0.82450                            \n",
      "[15]\tvalidation_0-auc:0.91368\tvalidation_1-auc:0.82694                            \n",
      "[16]\tvalidation_0-auc:0.91517\tvalidation_1-auc:0.82773                            \n",
      "[17]\tvalidation_0-auc:0.91618\tvalidation_1-auc:0.82749                            \n",
      "[18]\tvalidation_0-auc:0.91793\tvalidation_1-auc:0.82857                            \n",
      "[19]\tvalidation_0-auc:0.91924\tvalidation_1-auc:0.82875                            \n",
      "[20]\tvalidation_0-auc:0.92041\tvalidation_1-auc:0.82911                            \n",
      "[21]\tvalidation_0-auc:0.92131\tvalidation_1-auc:0.82875                            \n",
      "[22]\tvalidation_0-auc:0.92209\tvalidation_1-auc:0.82924                            \n",
      "[23]\tvalidation_0-auc:0.92355\tvalidation_1-auc:0.82936                            \n",
      "[24]\tvalidation_0-auc:0.92452\tvalidation_1-auc:0.82929                            \n",
      "[25]\tvalidation_0-auc:0.92505\tvalidation_1-auc:0.82968                            \n",
      "[26]\tvalidation_0-auc:0.92545\tvalidation_1-auc:0.82957                            \n",
      "[27]\tvalidation_0-auc:0.92570\tvalidation_1-auc:0.82939                            \n",
      "[28]\tvalidation_0-auc:0.92658\tvalidation_1-auc:0.82968                            \n",
      "[29]\tvalidation_0-auc:0.92682\tvalidation_1-auc:0.82916                            \n",
      "[0]\tvalidation_0-auc:0.79172\tvalidation_1-auc:0.73067                             \n",
      "[1]\tvalidation_0-auc:0.80679\tvalidation_1-auc:0.74603                             \n",
      "[2]\tvalidation_0-auc:0.81399\tvalidation_1-auc:0.75552                             \n",
      "[3]\tvalidation_0-auc:0.85313\tvalidation_1-auc:0.79894                             \n",
      "[4]\tvalidation_0-auc:0.85071\tvalidation_1-auc:0.79667                             \n",
      "[5]\tvalidation_0-auc:0.85979\tvalidation_1-auc:0.80917                             \n",
      "[6]\tvalidation_0-auc:0.86616\tvalidation_1-auc:0.81576                             \n",
      "[7]\tvalidation_0-auc:0.86983\tvalidation_1-auc:0.82099                             \n",
      "[8]\tvalidation_0-auc:0.87018\tvalidation_1-auc:0.81804                             \n",
      "[9]\tvalidation_0-auc:0.87585\tvalidation_1-auc:0.82419                             \n",
      "[10]\tvalidation_0-auc:0.87634\tvalidation_1-auc:0.82191                            \n",
      "[11]\tvalidation_0-auc:0.88193\tvalidation_1-auc:0.82438                            \n",
      "[12]\tvalidation_0-auc:0.88207\tvalidation_1-auc:0.82316                            \n",
      "[13]\tvalidation_0-auc:0.88217\tvalidation_1-auc:0.82200                            \n",
      "[14]\tvalidation_0-auc:0.88586\tvalidation_1-auc:0.82632                            \n",
      "[15]\tvalidation_0-auc:0.88669\tvalidation_1-auc:0.82477                            \n",
      "[16]\tvalidation_0-auc:0.89061\tvalidation_1-auc:0.82759                            \n",
      "[17]\tvalidation_0-auc:0.89114\tvalidation_1-auc:0.82635                            \n",
      "[18]\tvalidation_0-auc:0.89285\tvalidation_1-auc:0.82866                            \n",
      "[19]\tvalidation_0-auc:0.89432\tvalidation_1-auc:0.83015                            \n",
      "[20]\tvalidation_0-auc:0.89530\tvalidation_1-auc:0.83149                            \n",
      "[21]\tvalidation_0-auc:0.89616\tvalidation_1-auc:0.83171                            \n",
      "[22]\tvalidation_0-auc:0.89736\tvalidation_1-auc:0.83263                            \n",
      "[23]\tvalidation_0-auc:0.89747\tvalidation_1-auc:0.83279                            \n",
      "[24]\tvalidation_0-auc:0.89864\tvalidation_1-auc:0.83302                            \n",
      "[25]\tvalidation_0-auc:0.89918\tvalidation_1-auc:0.83345                            \n",
      "[26]\tvalidation_0-auc:0.89922\tvalidation_1-auc:0.83359                            \n",
      "[27]\tvalidation_0-auc:0.89989\tvalidation_1-auc:0.83360                            \n",
      "[28]\tvalidation_0-auc:0.90025\tvalidation_1-auc:0.83336                            \n",
      "[29]\tvalidation_0-auc:0.90049\tvalidation_1-auc:0.83279                            \n",
      "[0]\tvalidation_0-auc:0.77063\tvalidation_1-auc:0.73223                             \n",
      "[1]\tvalidation_0-auc:0.78021\tvalidation_1-auc:0.74055                             \n",
      "[2]\tvalidation_0-auc:0.78111\tvalidation_1-auc:0.74356                             \n",
      "[3]\tvalidation_0-auc:0.82308\tvalidation_1-auc:0.79010                             \n",
      "[4]\tvalidation_0-auc:0.81805\tvalidation_1-auc:0.78511                             \n",
      "[5]\tvalidation_0-auc:0.82958\tvalidation_1-auc:0.79702                             \n",
      "[6]\tvalidation_0-auc:0.83282\tvalidation_1-auc:0.80127                             \n",
      "[7]\tvalidation_0-auc:0.83610\tvalidation_1-auc:0.80638                             \n",
      "[8]\tvalidation_0-auc:0.83401\tvalidation_1-auc:0.80294                             \n",
      "[9]\tvalidation_0-auc:0.83772\tvalidation_1-auc:0.80801                             \n",
      "[10]\tvalidation_0-auc:0.83668\tvalidation_1-auc:0.80555                            \n",
      "[11]\tvalidation_0-auc:0.83955\tvalidation_1-auc:0.80919                            \n",
      "[12]\tvalidation_0-auc:0.84108\tvalidation_1-auc:0.81065                            \n",
      "[13]\tvalidation_0-auc:0.83956\tvalidation_1-auc:0.80920                            \n",
      "[14]\tvalidation_0-auc:0.84161\tvalidation_1-auc:0.81095                            \n",
      "[15]\tvalidation_0-auc:0.84308\tvalidation_1-auc:0.81228                            \n",
      "[16]\tvalidation_0-auc:0.84447\tvalidation_1-auc:0.81480                            \n",
      "[17]\tvalidation_0-auc:0.84589\tvalidation_1-auc:0.81783                            \n",
      "[18]\tvalidation_0-auc:0.84647\tvalidation_1-auc:0.81937                            \n",
      "[19]\tvalidation_0-auc:0.84699\tvalidation_1-auc:0.82026                            \n",
      "[20]\tvalidation_0-auc:0.84850\tvalidation_1-auc:0.82100                            \n",
      "[21]\tvalidation_0-auc:0.84762\tvalidation_1-auc:0.82089                            \n",
      "[22]\tvalidation_0-auc:0.84826\tvalidation_1-auc:0.82130                            \n",
      "[23]\tvalidation_0-auc:0.84919\tvalidation_1-auc:0.82162                            \n",
      "[24]\tvalidation_0-auc:0.84965\tvalidation_1-auc:0.82186                            \n",
      "[25]\tvalidation_0-auc:0.85008\tvalidation_1-auc:0.82242                            \n",
      "[26]\tvalidation_0-auc:0.85065\tvalidation_1-auc:0.82285                            \n",
      "[27]\tvalidation_0-auc:0.85117\tvalidation_1-auc:0.82358                            \n",
      "[28]\tvalidation_0-auc:0.85050\tvalidation_1-auc:0.82255                            \n",
      "[29]\tvalidation_0-auc:0.85060\tvalidation_1-auc:0.82239                            \n",
      "[0]\tvalidation_0-auc:0.78550\tvalidation_1-auc:0.73845                             \n",
      "[1]\tvalidation_0-auc:0.84586\tvalidation_1-auc:0.81245                             \n",
      "[2]\tvalidation_0-auc:0.85346\tvalidation_1-auc:0.81843                             \n",
      "[3]\tvalidation_0-auc:0.85782\tvalidation_1-auc:0.82328                             \n",
      "[4]\tvalidation_0-auc:0.85643\tvalidation_1-auc:0.81935                             \n",
      "[5]\tvalidation_0-auc:0.86238\tvalidation_1-auc:0.82479                             \n",
      "[6]\tvalidation_0-auc:0.86531\tvalidation_1-auc:0.82791                             \n",
      "[7]\tvalidation_0-auc:0.86635\tvalidation_1-auc:0.82911                             \n",
      "[8]\tvalidation_0-auc:0.86892\tvalidation_1-auc:0.83061                             \n",
      "[9]\tvalidation_0-auc:0.87016\tvalidation_1-auc:0.83071                             \n",
      "[10]\tvalidation_0-auc:0.87120\tvalidation_1-auc:0.83059                            \n",
      "[11]\tvalidation_0-auc:0.87391\tvalidation_1-auc:0.83140                            \n",
      "[12]\tvalidation_0-auc:0.87513\tvalidation_1-auc:0.83164                            \n",
      "[13]\tvalidation_0-auc:0.87596\tvalidation_1-auc:0.83237                            \n",
      "[14]\tvalidation_0-auc:0.87776\tvalidation_1-auc:0.83136                            \n",
      "[15]\tvalidation_0-auc:0.87918\tvalidation_1-auc:0.83194                            \n",
      "[16]\tvalidation_0-auc:0.88060\tvalidation_1-auc:0.83290                            \n",
      "[17]\tvalidation_0-auc:0.88166\tvalidation_1-auc:0.83272                            \n",
      "[18]\tvalidation_0-auc:0.88252\tvalidation_1-auc:0.83327                            \n",
      "[19]\tvalidation_0-auc:0.88358\tvalidation_1-auc:0.83367                            \n",
      "[20]\tvalidation_0-auc:0.88452\tvalidation_1-auc:0.83434                            \n",
      "[21]\tvalidation_0-auc:0.88532\tvalidation_1-auc:0.83477                            \n",
      "[22]\tvalidation_0-auc:0.88644\tvalidation_1-auc:0.83520                            \n",
      "[23]\tvalidation_0-auc:0.88719\tvalidation_1-auc:0.83489                            \n",
      "[24]\tvalidation_0-auc:0.88785\tvalidation_1-auc:0.83483                            \n",
      "[25]\tvalidation_0-auc:0.88833\tvalidation_1-auc:0.83453                            \n",
      "[26]\tvalidation_0-auc:0.88851\tvalidation_1-auc:0.83438                            \n",
      "[27]\tvalidation_0-auc:0.88890\tvalidation_1-auc:0.83460                            \n",
      "[28]\tvalidation_0-auc:0.88954\tvalidation_1-auc:0.83503                            \n",
      "[29]\tvalidation_0-auc:0.88998\tvalidation_1-auc:0.83534                            \n",
      "[0]\tvalidation_0-auc:0.81626\tvalidation_1-auc:0.72406                             \n",
      "[1]\tvalidation_0-auc:0.87427\tvalidation_1-auc:0.79415                             \n",
      "[2]\tvalidation_0-auc:0.86994\tvalidation_1-auc:0.78510                             \n",
      "[3]\tvalidation_0-auc:0.88358\tvalidation_1-auc:0.79944                             \n",
      "[4]\tvalidation_0-auc:0.88197\tvalidation_1-auc:0.79653                             \n",
      "[5]\tvalidation_0-auc:0.88633\tvalidation_1-auc:0.80661                             \n",
      "[6]\tvalidation_0-auc:0.89151\tvalidation_1-auc:0.81231                             \n",
      "[7]\tvalidation_0-auc:0.89275\tvalidation_1-auc:0.81663                             \n",
      "[8]\tvalidation_0-auc:0.89304\tvalidation_1-auc:0.81416                             \n",
      "[9]\tvalidation_0-auc:0.89543\tvalidation_1-auc:0.81598                             \n",
      "[10]\tvalidation_0-auc:0.89731\tvalidation_1-auc:0.81692                            \n",
      "[11]\tvalidation_0-auc:0.89839\tvalidation_1-auc:0.81922                            \n",
      "[12]\tvalidation_0-auc:0.89863\tvalidation_1-auc:0.82048                            \n",
      "[13]\tvalidation_0-auc:0.89966\tvalidation_1-auc:0.81907                            \n",
      "[14]\tvalidation_0-auc:0.90174\tvalidation_1-auc:0.82095                            \n",
      "[15]\tvalidation_0-auc:0.90305\tvalidation_1-auc:0.82218                            \n",
      "[16]\tvalidation_0-auc:0.90467\tvalidation_1-auc:0.82316                            \n",
      "[17]\tvalidation_0-auc:0.90540\tvalidation_1-auc:0.82397                            \n",
      "[18]\tvalidation_0-auc:0.90654\tvalidation_1-auc:0.82494                            \n",
      "[19]\tvalidation_0-auc:0.90760\tvalidation_1-auc:0.82532                            \n",
      "[20]\tvalidation_0-auc:0.90837\tvalidation_1-auc:0.82588                            \n",
      "[21]\tvalidation_0-auc:0.90891\tvalidation_1-auc:0.82655                            \n",
      "[22]\tvalidation_0-auc:0.90989\tvalidation_1-auc:0.82679                            \n",
      "[23]\tvalidation_0-auc:0.91092\tvalidation_1-auc:0.82668                            \n",
      "[24]\tvalidation_0-auc:0.91156\tvalidation_1-auc:0.82697                            \n",
      "[25]\tvalidation_0-auc:0.91214\tvalidation_1-auc:0.82708                            \n",
      "[26]\tvalidation_0-auc:0.91264\tvalidation_1-auc:0.82690                            \n",
      "[27]\tvalidation_0-auc:0.91327\tvalidation_1-auc:0.82668                            \n",
      "[28]\tvalidation_0-auc:0.91409\tvalidation_1-auc:0.82629                            \n",
      "[29]\tvalidation_0-auc:0.91440\tvalidation_1-auc:0.82674                            \n",
      "[0]\tvalidation_0-auc:0.79966\tvalidation_1-auc:0.73853                             \n",
      "[1]\tvalidation_0-auc:0.81370\tvalidation_1-auc:0.75323                             \n",
      "[2]\tvalidation_0-auc:0.82039\tvalidation_1-auc:0.75679                             \n",
      "[3]\tvalidation_0-auc:0.86135\tvalidation_1-auc:0.79896                             \n",
      "[4]\tvalidation_0-auc:0.85970\tvalidation_1-auc:0.79689                             \n",
      "[5]\tvalidation_0-auc:0.86840\tvalidation_1-auc:0.81129                             \n",
      "[6]\tvalidation_0-auc:0.87426\tvalidation_1-auc:0.81784                             \n",
      "[7]\tvalidation_0-auc:0.87346\tvalidation_1-auc:0.81377                             \n",
      "[8]\tvalidation_0-auc:0.87440\tvalidation_1-auc:0.81331                             \n",
      "[9]\tvalidation_0-auc:0.88286\tvalidation_1-auc:0.82047                             \n",
      "[10]\tvalidation_0-auc:0.88385\tvalidation_1-auc:0.81760                            \n",
      "[11]\tvalidation_0-auc:0.89053\tvalidation_1-auc:0.82262                            \n",
      "[12]\tvalidation_0-auc:0.89008\tvalidation_1-auc:0.82166                            \n",
      "[13]\tvalidation_0-auc:0.89168\tvalidation_1-auc:0.82035                            \n",
      "[14]\tvalidation_0-auc:0.89325\tvalidation_1-auc:0.82004                            \n",
      "[15]\tvalidation_0-auc:0.89347\tvalidation_1-auc:0.81932                            \n",
      "[16]\tvalidation_0-auc:0.89888\tvalidation_1-auc:0.82438                            \n",
      "[17]\tvalidation_0-auc:0.90004\tvalidation_1-auc:0.82280                            \n",
      "[18]\tvalidation_0-auc:0.90368\tvalidation_1-auc:0.82590                            \n",
      "[19]\tvalidation_0-auc:0.90645\tvalidation_1-auc:0.82825                            \n",
      "[20]\tvalidation_0-auc:0.90931\tvalidation_1-auc:0.83055                            \n",
      "[21]\tvalidation_0-auc:0.90977\tvalidation_1-auc:0.83097                            \n",
      "[22]\tvalidation_0-auc:0.91123\tvalidation_1-auc:0.83146                            \n",
      "[23]\tvalidation_0-auc:0.91292\tvalidation_1-auc:0.83008                            \n",
      "[24]\tvalidation_0-auc:0.91415\tvalidation_1-auc:0.83080                            \n",
      "[25]\tvalidation_0-auc:0.91490\tvalidation_1-auc:0.83106                            \n",
      "[26]\tvalidation_0-auc:0.91547\tvalidation_1-auc:0.83165                            \n",
      "[27]\tvalidation_0-auc:0.91599\tvalidation_1-auc:0.83260                            \n",
      "[28]\tvalidation_0-auc:0.91625\tvalidation_1-auc:0.83240                            \n",
      "[29]\tvalidation_0-auc:0.91668\tvalidation_1-auc:0.83253                            \n",
      "[0]\tvalidation_0-auc:0.79968\tvalidation_1-auc:0.73605                             \n",
      "[1]\tvalidation_0-auc:0.81519\tvalidation_1-auc:0.74855                             \n",
      "[2]\tvalidation_0-auc:0.81823\tvalidation_1-auc:0.75362                             \n",
      "[3]\tvalidation_0-auc:0.86180\tvalidation_1-auc:0.79509                             \n",
      "[4]\tvalidation_0-auc:0.85930\tvalidation_1-auc:0.79188                             \n",
      "[5]\tvalidation_0-auc:0.86918\tvalidation_1-auc:0.80653                             \n",
      "[6]\tvalidation_0-auc:0.87481\tvalidation_1-auc:0.81307                             \n",
      "[7]\tvalidation_0-auc:0.87382\tvalidation_1-auc:0.80972                             \n",
      "[8]\tvalidation_0-auc:0.87489\tvalidation_1-auc:0.80861                             \n",
      "[9]\tvalidation_0-auc:0.88045\tvalidation_1-auc:0.81355                             \n",
      "[10]\tvalidation_0-auc:0.87992\tvalidation_1-auc:0.80884                            \n",
      "[11]\tvalidation_0-auc:0.88553\tvalidation_1-auc:0.81351                            \n",
      "[12]\tvalidation_0-auc:0.88450\tvalidation_1-auc:0.81257                            \n",
      "[13]\tvalidation_0-auc:0.88485\tvalidation_1-auc:0.81055                            \n",
      "[14]\tvalidation_0-auc:0.88524\tvalidation_1-auc:0.81016                            \n",
      "[15]\tvalidation_0-auc:0.88513\tvalidation_1-auc:0.80779                            \n",
      "[16]\tvalidation_0-auc:0.88912\tvalidation_1-auc:0.81189                            \n",
      "[17]\tvalidation_0-auc:0.88994\tvalidation_1-auc:0.81107                            \n",
      "[18]\tvalidation_0-auc:0.89331\tvalidation_1-auc:0.81554                            \n",
      "[19]\tvalidation_0-auc:0.89601\tvalidation_1-auc:0.81785                            \n",
      "[20]\tvalidation_0-auc:0.89837\tvalidation_1-auc:0.82090                            \n",
      "[21]\tvalidation_0-auc:0.89828\tvalidation_1-auc:0.81895                            \n",
      "[22]\tvalidation_0-auc:0.90059\tvalidation_1-auc:0.82129                            \n",
      "[23]\tvalidation_0-auc:0.90166\tvalidation_1-auc:0.82040                            \n",
      "[24]\tvalidation_0-auc:0.90354\tvalidation_1-auc:0.82248                            \n",
      "[25]\tvalidation_0-auc:0.90470\tvalidation_1-auc:0.82460                            \n",
      "[26]\tvalidation_0-auc:0.90612\tvalidation_1-auc:0.82594                            \n",
      "[27]\tvalidation_0-auc:0.90782\tvalidation_1-auc:0.82639                            \n",
      "[28]\tvalidation_0-auc:0.90854\tvalidation_1-auc:0.82552                            \n",
      "[29]\tvalidation_0-auc:0.90875\tvalidation_1-auc:0.82514                            \n",
      "100%|██████████| 50/50 [05:50<00:00,  7.00s/trial, best loss: -0.8363391040488652]\n",
      "best: {'colsample_bytree': 0.6554455427227177, 'learning_rate': 0.1448084223682485, 'max_depth': 6.0, 'min_child_weight': 5.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin,tpe,Trials\n",
    "\n",
    "trials=Trials()\n",
    "\n",
    "best=fmin(fn=objective_func,\n",
    "          space=xgb_search_space,\n",
    "          algo=tpe.suggest,\n",
    "          max_evals=50,\n",
    "          trials=trials, rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:',best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#튜닝된 XGBoost 모델에서 피처 중요도\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax=plt.subplots(1,1,figsize=(10,8))\n",
    "plot_importance(xgb_clf,ax=ax,max_num_features=20,height=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbmNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.22.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.11.4)\n",
      "Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 1.3/1.3 MB 14.3 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1658, number of negative: 40913\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13308\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 242\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038947 -> initscore=-3.205836\n",
      "[LightGBM] [Info] Start training from score -3.205836\n",
      "ROC AUC: 0.8134\n"
     ]
    }
   ],
   "source": [
    "#LightGBM 모델 학습\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf=LGBMClassifier(n_estimators=500)\n",
    "\n",
    "eval_set=[(X_tr,y_tr),(X_val,y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_metric='auc', eval_set=eval_set )\n",
    "lgbm_roc_score=roc_auc_score(y_test,lgbm_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search_space={'num_leaves':hp.quniform('num_leaves',32,64,1),\n",
    "                   'max_depth':hp.quniform('max_depth',100,160,1),\n",
    "                   'min_child_samples':hp.quniform('min_child_samples',60,100,1),\n",
    "                   'subsample':hp.uniform('subsample',0.7,1),\n",
    "                   'learning_rate':hp.uniform('learning_rate',0.01,0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space): \n",
    "    lgbm_clf = LGBMClassifier(n_estimators=100,\n",
    "                              num_leaves=int(search_space['num_leaves']), \n",
    "                              max_depth=int(search_space['max_depth']), \n",
    "                              min_child_samples=int(search_space['min_child_samples']), \n",
    "                              subsample=search_space['subsample'], \n",
    "                              learning_rate=search_space['learning_rate'])\n",
    "    \n",
    "    roc_auc_list=[]\n",
    "    \n",
    "    #3개-K-fold 방식 적용\n",
    "    kf=KFold(n_splits=3)\n",
    "    \n",
    "    #X_train -> X_tr / X_val 분류\n",
    "    for tr_index,val_index in kf.split(X_train):#kf.split(X_train)으로 tr/val index 나옴\n",
    "        X_tr,y_tr=X_train.iloc[tr_index],y_train.iloc[tr_index]\n",
    "        X_val,y_val=X_train.iloc[val_index],y_train.iloc[val_index]\n",
    "        \n",
    "        lgbm_clf.fit(X_tr,y_tr,eval_metric='auc',\n",
    "                     eval_set=[(X_tr,y_tr),(X_val,y_val)])\n",
    "        \n",
    "        score=roc_auc_score(y_val,lgbm_clf.predict_proba(X_val)[:,1])\n",
    "        roc_auc_list.append(score)\n",
    "        \n",
    "    return (-1)*np.mean(roc_auc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (1.22.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (1.11.4)\n",
      "Requirement already satisfied: six in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (3.2.1)\n",
      "Requirement already satisfied: future in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (4.66.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (3.0.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->hyperopt) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\janenahm\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.22.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 61.0/61.0 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 15.8/15.8 MB 31.2 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.0\n",
      "    Uninstalling numpy-1.22.0:\n",
      "      Successfully uninstalled numpy-1.22.0\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\JaneNahm\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872 \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281 \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465 \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965            \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12885                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872  \n",
      "[LightGBM] [Info] Start training from score -3.205872                            \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281  \n",
      "[LightGBM] [Info] Start training from score -3.186281                            \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465  \n",
      "[LightGBM] [Info] Start training from score -3.218465                            \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872  \n",
      "[LightGBM] [Info] Start training from score -3.205872                            \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281  \n",
      "[LightGBM] [Info] Start training from score -3.186281                            \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465  \n",
      "[LightGBM] [Info] Start training from score -3.218465                            \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872  \n",
      "[LightGBM] [Info] Start training from score -3.205872                            \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281  \n",
      "[LightGBM] [Info] Start training from score -3.186281                            \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465  \n",
      "[LightGBM] [Info] Start training from score -3.218465                            \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872  \n",
      "[LightGBM] [Info] Start training from score -3.205872                            \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281  \n",
      "[LightGBM] [Info] Start training from score -3.186281                            \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465  \n",
      "[LightGBM] [Info] Start training from score -3.218465                            \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872  \n",
      "[LightGBM] [Info] Start training from score -3.205872                            \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281  \n",
      "[LightGBM] [Info] Start training from score -3.186281                            \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465  \n",
      "[LightGBM] [Info] Start training from score -3.218465                            \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872  \n",
      "[LightGBM] [Info] Start training from score -3.205872                            \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281  \n",
      "[LightGBM] [Info] Start training from score -3.186281                            \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465  \n",
      "[LightGBM] [Info] Start training from score -3.218465                            \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872  \n",
      "[LightGBM] [Info] Start training from score -3.205872                            \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281  \n",
      "[LightGBM] [Info] Start training from score -3.186281                            \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465  \n",
      "[LightGBM] [Info] Start training from score -3.218465                            \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965            \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872  \n",
      "[LightGBM] [Info] Start training from score -3.205872                            \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281  \n",
      "[LightGBM] [Info] Start training from score -3.186281                            \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465  \n",
      "[LightGBM] [Info] Start training from score -3.218465                            \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872  \n",
      "[LightGBM] [Info] Start training from score -3.205872                            \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281  \n",
      "[LightGBM] [Info] Start training from score -3.186281                            \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984            \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465  \n",
      "[LightGBM] [Info] Start training from score -3.218465                            \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13094                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13050                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12835                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12863                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12926                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13094                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12954                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.314144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12926                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13094                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13037                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13050                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12954                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13094                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12946                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872   \n",
      "[LightGBM] [Info] Start training from score -3.205872                             \n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281   \n",
      "[LightGBM] [Info] Start training from score -3.186281                             \n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984             \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465   \n",
      "[LightGBM] [Info] Start training from score -3.218465                             \n",
      "100%|██████████| 50/50 [09:26<00:00, 11.34s/trial, best loss: -0.8355905239520475]\n",
      "best: {'learning_rate': 0.03564213029580296, 'max_depth': 134.0, 'min_child_samples': 96.0, 'num_leaves': 32.0, 'subsample': 0.8545803136660588}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials \n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective_func, space=lgbm_search_space , algo=tpe.suggest, \n",
    "            max_evals=50, trials=trials, rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:',best)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1658, number of negative: 40913\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12898\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038947 -> initscore=-3.205836\n",
      "[LightGBM] [Info] Start training from score -3.205836\n",
      "ROC AUC: 0.8417\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf=LGBMClassifier(n_estimators=500,num_leaves=int(best['num_leaves']),\n",
    "                        max_depth=int(best['max_depth']),\n",
    "                        min_child_samples=int(best['min_child_samples']),\n",
    "                        subsample=round(best['subsample'],5),\n",
    "                        learning_rate=round(best['learning_rate'],5)\n",
    "                        )\n",
    "\n",
    "lgbm_clf.fit(X_tr,y_tr,\n",
    "             eval_metric='auc',eval_set=[(X_tr,y_tr),(X_val,y_val)])\n",
    "\n",
    "lgbm_roc_score=roc_auc_score(y_test,xgb_clf.predict_proba(X_test)[:,1])\n",
    "print(\"ROC AUC: {0:.4f}\".format(lgbm_roc_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
